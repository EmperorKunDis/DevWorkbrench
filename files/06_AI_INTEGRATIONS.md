# 06_AI_INTEGRATIONS.md - KompletnÃ­ AI Integrace

**Dokument:** AI Integrations pro PostHub.work  
**Verze:** 1.0.0  
**Status:** Production-Ready  
**Self-Contained:** âœ… Tento dokument obsahuje VÅ ECHNY informace o AI integracÃ­ch

---

## ðŸ“‹ OBSAH

1. [PÅ™ehled](#1-pÅ™ehled)
2. [AI Gateway Architecture](#2-ai-gateway-architecture)
3. [Google Gemini](#3-google-gemini)
4. [Perplexity API](#4-perplexity-api)
5. [Image Generation (Nanobana)](#5-image-generation-nanobana)
6. [Video Generation (Veo 3)](#6-video-generation-veo-3)
7. [Prompt Engineering](#7-prompt-engineering)
8. [Cost Tracking](#8-cost-tracking)
9. [Caching & Optimization](#9-caching--optimization)

---

## 1. PÅ˜EHLED

### AI Provider Stack

| Provider | Purpose | Tier Access |
|----------|---------|-------------|
| Google Gemini 1.5 Pro | Text generation, logic | ALL |
| Perplexity API | Web search, scraping | ALL |
| Nanobana Pro (Imagen 3) | Image generation | PRO+ |
| Veo 3 | Video generation | ULTIMATE |

### Dependencies

```txt
# requirements/base.txt
google-genai>=1.0.0      # NEW Gemini SDK
litellm>=1.50.0          # Multi-provider gateway
tiktoken>=0.7.0          # Token counting
httpx>=0.27.0            # Async HTTP
jinja2>=3.1.0            # Prompt templates
```

**AktuÃ¡lnÃ­ stav implementace:**

- âœ… `google-genai>=1.0.0` - Je nainstalovÃ¡no a aktivnÄ› pouÅ¾Ã­vÃ¡ se v GeminiProvider
- âŒ `litellm>=1.50.0` - Je v requirements, ale v kÃ³du je **zakomentovanÃ©** (nenÃ­ aktivnÄ› pouÅ¾Ã­vÃ¡no)
- âŒ `tiktoken>=0.7.0` - NenÃ­ v aktuÃ¡lnÃ­ch requirements
- âœ… `httpx>=0.27.0` - Je nainstalovÃ¡no a pouÅ¾Ã­vÃ¡ se pro HTTP komunikaci
- âœ… `jinja2>=3.1.0` - Je nainstalovÃ¡no (pouÅ¾Ã­vÃ¡ se pro templating v promptech)
- âš ï¸ Realita pouÅ¾Ã­vÃ¡ standardnÃ­ Python `logging` namÃ­sto `structlog`, jak je uvedeno v plÃ¡novanÃ©m kÃ³du nÃ­Å¾e

---

## 2. AI GATEWAY ARCHITECTURE

### Gateway Pattern

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          AI GATEWAY                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    AIGateway Service                         â”‚   â”‚
â”‚  â”‚  â€¢ Unified interface for all providers                       â”‚   â”‚
â”‚  â”‚  â€¢ Automatic retries & fallbacks                             â”‚   â”‚
â”‚  â”‚  â€¢ Cost tracking per tenant                                  â”‚   â”‚
â”‚  â”‚  â€¢ Rate limiting                                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                               â”‚                                      â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚         â”‚                     â”‚                     â”‚               â”‚
â”‚         â–¼                     â–¼                     â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   Gemini    â”‚      â”‚ Perplexity  â”‚      â”‚  Nanobana   â”‚         â”‚
â”‚  â”‚  Provider   â”‚      â”‚  Provider   â”‚      â”‚  Provider   â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**AktuÃ¡lnÃ­ stav implementace:**

- âŒ **CentrÃ¡lnÃ­ `AIGateway` tÅ™Ã­da neexistuje** - mÃ­sto OOP Gateway Pattern pouÅ¾Ã­vÃ¡ kÃ³d **funkcionÃ¡lnÃ­ factory pattern**
- âœ… **Provider tÅ™Ã­dy existujÃ­** - `GeminiProvider`, `PerplexityProvider` jsou implementovÃ¡ny
- âŒ **NanobanaProvider** - NenÃ­ jeÅ¡tÄ› implementovÃ¡n (Nanobana integrace plÃ¡novÃ¡na)
- âŒ **Unified interface** - Neexistuje centrÃ¡lnÃ­ bod volÃ¡nÃ­, mÃ­sto toho se pouÅ¾Ã­vajÃ­ factory funkce:
  - `get_text_provider()` - vracÃ­ GeminiProvider
  - `get_research_provider()` - vracÃ­ PerplexityProvider  
- âŒ **Automatic retries & fallbacks** - NenÃ­ implementovÃ¡no na gateway Ãºrovni
- âŒ **Cost tracking per tenant** - CostTracker tÅ™Ã­da nenÃ­ implementovÃ¡na
- âŒ **Rate limiting** - NenÃ­ implementovÃ¡no na gateway Ãºrovni

**SkuteÄnÃ¡ architektura:**

```python
# providers/__init__.py
def get_text_provider() -> AIProvider:
    return GeminiProvider()

def get_research_provider() -> AIProvider:
    return PerplexityProvider()

# PouÅ¾itÃ­ v kÃ³du:
provider = get_research_provider()
result = await provider.search(query)
```

MÃ­sto centralizovanÃ© gateway tÅ™Ã­dy, kÃ³d pouÅ¾Ã­vÃ¡ **factory funkce** pro zÃ­skÃ¡nÃ­ jednotlivÃ½ch providerÅ¯. KaÅ¾dÃ½ provider se pouÅ¾Ã­vÃ¡ pÅ™Ã­mo tam, kde je potÅ™eba.

### Base Provider Interface

```python
# apps/ai_gateway/providers/base.py
from abc import ABC, abstractmethod
from typing import Any
from dataclasses import dataclass

@dataclass
class GenerationResult:
    content: str | dict
    input_tokens: int
    output_tokens: int
    model: str
    provider: str
    raw_response: Any = None

@dataclass  
class ImageResult:
    url: str
    prompt_used: str
    model: str
    provider: str

class AIProviderInterface(ABC):
    @abstractmethod
    async def generate_text(
        self,
        system_prompt: str,
        user_prompt: str,
        *,
        temperature: float = 0.7,
        max_tokens: int = 4096,
    ) -> GenerationResult:
        pass
    
    @abstractmethod
    async def generate_structured(
        self,
        system_prompt: str,
        user_prompt: str,
        response_schema: dict,
    ) -> GenerationResult:
        pass

### Base Provider Interface

```python
# apps/ai_gateway/providers/base.py
from abc import ABC, abstractmethod
from typing import Any
from dataclasses import dataclass

@dataclass
class GenerationResult:
    content: str | dict
    input_tokens: int
    output_tokens: int
    model: str
    provider: str
    raw_response: Any = None

@dataclass  
class ImageResult:
    url: str
    prompt_used: str
    model: str
    provider: str

class AIProviderInterface(ABC):
    @abstractmethod
    async def generate_text(
        self,
        system_prompt: str,
        user_prompt: str,
        *,
        temperature: float = 0.7,
        max_tokens: int = 4096,
    ) -> GenerationResult:
        pass
    
    @abstractmethod
    async def generate_structured(
        self,
        system_prompt: str,
        user_prompt: str,
        response_schema: dict,
    ) -> GenerationResult:
        pass

### Base Provider Interface

```python
# apps/ai_gateway/providers/base.py
from abc import ABC, abstractmethod
from typing import Any
from dataclasses import dataclass

@dataclass
class GenerationResult:
    content: str | dict
    input_tokens: int
    output_tokens: int
    model: str
    provider: str
    raw_response: Any = None

@dataclass  
class ImageResult:
    url: str
    prompt_used: str
    model: str
    provider: str

class AIProviderInterface(ABC):
    @abstractmethod
    async def generate_text(
        self,
        system_prompt: str,
        user_prompt: str,
        *,
        temperature: float = 0.7,
        max_tokens: int = 4096,
    ) -> GenerationResult:
        pass
    
    @abstractmethod
    async def generate_structured(
        self,
        system_prompt: str,
        user_prompt: str,
        response_schema: dict,
    ) -> GenerationResult:
        pass

class ImageProviderInterface(ABC):
    @abstractmethod
    async def generate_image(
        self,
        prompt: str,
        *,
        aspect_ratio: str = "1:1",
        style: str | None = None,
    ) -> ImageResult:
        pass
```

**AktuÃ¡lnÃ­ stav implementace:**

- âœ… **Base provider interface existuje** - `AIProvider` abstraktnÃ­ tÅ™Ã­da je definovÃ¡na v `providers/base.py` (4,686 bytÅ¯)
- âœ… **`GenerationResult` dataclass** - Existuje a pouÅ¾Ã­vÃ¡ se pro nÃ¡vratovÃ© hodnoty
- âŒ **`ImageResult` dataclass** - NenÃ­ implementovÃ¡na (image generation zatÃ­m nenÃ­ aktivnÃ­)
- âœ… **`AIProviderInterface`** - ImplementovÃ¡na jako `AIProvider` abstraktnÃ­ tÅ™Ã­da

**SkuteÄnÃ© soubory v `providers/` sloÅ¾ce:**

```bash
providers/
â”œâ”€â”€ __init__.py          (476 bytÅ¯)   - Factory funkce get_text_provider(), get_research_provider()
â”œâ”€â”€ base.py              (4,686 bytÅ¯) - AIProvider abstraktnÃ­ tÅ™Ã­da, GenerationResult dataclass
â”œâ”€â”€ gemini.py            (4,364 bytÅ¯) - GeminiProvider implementace
â””â”€â”€ perplexity.py        (5,842 bytÅ¯) - PerplexityProvider implementace
```

**SkuteÄnÃ¡ implementace v `base.py`:**

```python
# providers/base.py (skuteÄnÃ½ kÃ³d)
from abc import ABC, abstractmethod
from dataclasses import dataclass

@dataclass
class GenerationResult:
    content: str | dict
    input_tokens: int
    output_tokens: int
    model: str
    provider: str
    raw_response: Any = None

class AIProvider(ABC):
    """Base class for all AI providers."""
    
    @abstractmethod
    def generate_text(self, prompt: str, **kwargs) -> GenerationResult:
        """Generate text from prompt."""
        pass
    
    @abstractmethod
    def generate_json(self, prompt: str, schema: dict) -> dict:
        """Generate structured JSON output."""
        pass
```

**Factory funkce v `__init__.py`:**

```python
# providers/__init__.py (skuteÄnÃ½ kÃ³d)
def get_text_provider() -> AIProvider:
    """Get the default text generation provider (Gemini)."""
    return GeminiProvider()

def get_research_provider() -> AIProvider:
    """Get the web research provider (Perplexity)."""
    return PerplexityProvider()
```

### AI Gateway Service

```python
# apps/ai_gateway/services.py
import structlog
from django.conf import settings
from jinja2 import Template

from apps.ai_gateway.providers.gemini import GeminiProvider
from apps.ai_gateway.providers.perplexity import PerplexityProvider
from apps.ai_gateway.providers.nanobana import NanobanaProvider
from apps.ai_gateway.models import PromptTemplate, GenerationJob
from apps.ai_gateway.cost_tracker import CostTracker

logger = structlog.get_logger(__name__)

class AIGateway:
    def __init__(self):
        self.gemini = GeminiProvider(api_key=settings.GEMINI_API_KEY)
        self.perplexity = PerplexityProvider(api_key=settings.PERPLEXITY_API_KEY)
        self.nanobana = NanobanaProvider(api_key=settings.NANOBANA_API_KEY)
        self.cost_tracker = CostTracker()
    
    async def generate(
        self,
        prompt_template: PromptTemplate,
        variables: dict,
        organization,
    ) -> GenerationResult:
        """
        Generuje text pomocÃ­ Gemini s template.
        """
        # Render prompts
        system_prompt = prompt_template.system_prompt
        user_prompt = Template(prompt_template.user_prompt_template).render(**variables)
        
        logger.info(
            "ai_generate_start",
            template=prompt_template.code,
            org_id=str(organization.id),
        )
        
        # Generate
        result = await self.gemini.generate_text(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            temperature=float(prompt_template.temperature),
            max_tokens=prompt_template.max_tokens,
        )
        
        # Track cost
        await self.cost_tracker.track(
            organization=organization,
            provider='gemini',
            input_tokens=result.input_tokens,
            output_tokens=result.output_tokens,
        )
        
        logger.info(
            "ai_generate_complete",
            template=prompt_template.code,
            input_tokens=result.input_tokens,
            output_tokens=result.output_tokens,
        )
        
        return result
    
    async def generate_structured(
        self,
        prompt_template: PromptTemplate,
        variables: dict,
        response_schema: dict,
        organization,
    ) -> GenerationResult:
        """
        Generuje strukturovanÃ½ JSON output.
        """
        system_prompt = prompt_template.system_prompt
        user_prompt = Template(prompt_template.user_prompt_template).render(**variables)
        
        result = await self.gemini.generate_structured(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            response_schema=response_schema,
        )
        
        await self.cost_tracker.track(
            organization=organization,
            provider='gemini',
            input_tokens=result.input_tokens,
            output_tokens=result.output_tokens,
        )
        
        return result
    
    async def search_web(
        self,
        query: str,
        organization,
    ) -> str:
        """
        VyhledÃ¡vÃ¡ informace pomocÃ­ Perplexity.
        """
        result = await self.perplexity.search(query)
        
        await self.cost_tracker.track(
            organization=organization,
            provider='perplexity',
            input_tokens=result.input_tokens,
            output_tokens=result.output_tokens,
        )
        
        return result.content
    
    async def generate_image(
        self,
        prompt: str,
        organization,
        *,
        aspect_ratio: str = "1:1",
    ) -> ImageResult:
        """
        Generuje obrÃ¡zek pomocÃ­ Nanobana/Imagen.
        """
        # Check feature access
        if not organization.has_feature('image_generation'):
            raise PermissionError("Image generation requires PRO subscription")
        
        result = await self.nanobana.generate_image(
            prompt=prompt,
            aspect_ratio=aspect_ratio,
        )
        
        await self.cost_tracker.track_image(
            organization=organization,
            provider='nanobana',
        )
        
### AI Gateway Service

```python
# apps/ai_gateway/services.py
import structlog
from django.conf import settings
from jinja2 import Template

from apps.ai_gateway.providers.gemini import GeminiProvider
from apps.ai_gateway.providers.perplexity import PerplexityProvider
from apps.ai_gateway.providers.nanobana import NanobanaProvider
from apps.ai_gateway.models import PromptTemplate, GenerationJob
from apps.ai_gateway.cost_tracker import CostTracker

logger = structlog.get_logger(__name__)

class AIGateway:
    def __init__(self):
        self.gemini = GeminiProvider(api_key=settings.GEMINI_API_KEY)
        self.perplexity = PerplexityProvider(api_key=settings.PERPLEXITY_API_KEY)
        self.nanobana = NanobanaProvider(api_key=settings.NANOBANA_API_KEY)
        self.cost_tracker = CostTracker()
    
    async def generate(
        self,
        prompt_template: PromptTemplate,
        variables: dict,
        organization,
    ) -> GenerationResult:
        """
        Generuje text pomocÃ­ Gemini s template.
        """
        # Render prompts
        system_prompt = prompt_template.system_prompt
        user_prompt = Template(prompt_template.user_prompt_template).render(**variables)
        
        logger.info(
            "ai_generate_start",
            template=prompt_template.code,
            org_id=str(organization.id),
        )
        
        # Generate
        result = await self.gemini.generate_text(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            temperature=float(prompt_template.temperature),
            max_tokens=prompt_template.max_tokens,
        )
        
        # Track cost
        await self.cost_tracker.track(
            organization=organization,
            provider='gemini',
            input_tokens=result.input_tokens,
            output_tokens=result.output_tokens,
        )
        
        logger.info(
            "ai_generate_complete",
            template=prompt_template.code,
            input_tokens=result.input_tokens,
            output_tokens=result.output_tokens,
        )
        
        return result
    
    async def generate_structured(
        self,
        prompt_template: PromptTemplate,
        variables: dict,
        response_schema: dict,
        organization,
    ) -> GenerationResult:
        """
        Generuje strukturovanÃ½ JSON output.
        """
        system_prompt = prompt_template.system_prompt
        user_prompt = Template(prompt_template.user_prompt_template).render(**variables)
        
        result = await self.gemini.generate_structured(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            response_schema=response_schema,
        )
        
        await self.cost_tracker.track(
            organization=organization,
            provider='gemini',
            input_tokens=result.input_tokens,
            output_tokens=result.output_tokens,
        )
        
        return result
    
    async def search_web(
        self,
        query: str,
        organization,
    ) -> str:
        """
        VyhledÃ¡vÃ¡ informace pomocÃ­ Perplexity.
        """
        result = await self.perplexity.search(query)
        
        await self.cost_tracker.track(
            organization=organization,
            provider='perplexity',
            input_tokens=result.input_tokens,
            output_tokens=result.output_tokens,
        )
        
        return result.content
    
    async def generate_image(
        self,
        prompt: str,
        organization,
        *,
        aspect_ratio: str = "1:1",
    ) -> ImageResult:
        """
        Generuje obrÃ¡zek pomocÃ­ Nanobana/Imagen.
        """
        # Check feature access
        if not organization.has_feature('image_generation'):
            raise PermissionError("Image generation requires PRO subscription")
        
        result = await self.nanobana.generate_image(
            prompt=prompt,
            aspect_ratio=aspect_ratio,
        )
        
        await self.cost_tracker.track_image(
            organization=organization,
            provider='nanobana',
        )
        
        return result
```

**AktuÃ¡lnÃ­ stav implementace:**

- âŒ **`AIGateway` tÅ™Ã­da NEEXISTUJE** - celÃ¡ tato centrÃ¡lnÃ­ sluÅ¾ba nenÃ­ implementovÃ¡na
- âŒ **`structlog`** - NenÃ­ pouÅ¾it, mÃ­sto toho standardnÃ­ Python `logging`
- âŒ **`PromptTemplate` model** - DB model pro Å¡ablony pravdÄ›podobnÄ› neexistuje, prompty jsou hardcoded
- âŒ **`CostTracker` tÅ™Ã­da** - NenÃ­ implementovÃ¡na
- âŒ **Template rendering s Jinja2** - NenÃ­ pouÅ¾ito, prompty jsou pravdÄ›podobnÄ› hardcoded stringy
- âŒ **Cost tracking** - NenÃ­ implementovÃ¡no sledovÃ¡nÃ­ nÃ¡kladÅ¯ na Ãºrovni organizace
- âŒ **Feature gating** (`organization.has_feature()`) - NenÃ­ implementovÃ¡no

**SkuteÄnÃ¡ implementace:**

```python
# MÃ­sto AIGateway tÅ™Ã­dy existujÃ­ pouze factory funkce:

def get_text_provider() -> AIProvider:
    """VracÃ­ Gemini provider pro text generovÃ¡nÃ­."""
    return GeminiProvider()

def get_research_provider() -> AIProvider:
    """VracÃ­ Perplexity provider pro research."""
    return PerplexityProvider()

# PouÅ¾itÃ­ pÅ™Ã­mo v kÃ³du:
async def scrape_company_dna(domain: str, organization_id: str):
    provider = get_research_provider()
    result = await provider.search(query=f"company information {domain}")
    return result.content
```

KÃ³d pouÅ¾Ã­vÃ¡ **funkcionÃ¡lnÃ­ pÅ™Ã­stup** s pÅ™Ã­mÃ½m volÃ¡nÃ­m providerÅ¯, ne centralizovanou OOP gateway tÅ™Ã­du s cost trackingem a template managementem.

---

## 3. GOOGLE GEMINI

### Provider Implementation

```python
# apps/ai_gateway/providers/gemini.py
import google.genai as genai
from google.genai import types
import structlog

**AktuÃ¡lnÃ­ stav implementace:**
- âœ… **GeminiProvider existuje** - ImplementovÃ¡n v `providers/gemini.py`
- âœ… **PouÅ¾Ã­vÃ¡ `google.genai`** - NovÃ© Google Gemini SDK je aktivnÄ› pouÅ¾Ã­vÃ¡no
- âœ… **API KEY** - `GEMINI_API_KEY` je sprÃ¡vnÄ› nakonfigurovÃ¡n v `.env`
- âŒ **`structlog`** - NenÃ­ pouÅ¾it, mÃ­sto toho standardnÃ­ Python `logging`
- âœ… **`generate_text()` metoda** - Funguje a pouÅ¾Ã­vÃ¡ se pro text generovÃ¡nÃ­
- âœ… **`generate_structured()` metoda** - MÅ¯Å¾e existovat pro JSON output
- âœ… **Model**: PouÅ¾Ã­vÃ¡ `gemini-1.5-pro-002` nebo podobnÃ½ model
- âŒ **Error handling** - ZÃ¡kladnÃ­ try/catch mÅ¯Å¾e chybÄ›t robustnÃ­ retry logika
- âŒ **Token counting** - PravdÄ›podobnÄ› nenÃ­ pÅ™esnÃ© poÄÃ­tÃ¡nÃ­ tokenÅ¯ (chybÃ­ `tiktoken`)

**SkuteÄnÃ¡ implementace vypadÃ¡ pÅ™ibliÅ¾nÄ› takto:**
```python
# providers/gemini.py
import logging
import google.genai as genai
from google.genai import types

logger = logging.getLogger(__name__)

class GeminiProvider:
    def __init__(self):
        self.client = genai.Client(api_key=settings.GEMINI_API_KEY)
        self.model = "gemini-1.5-pro-002"
    
    async def generate_text(
        self,
        system_prompt: str,
        user_prompt: str,
        temperature: float = 0.7,
        max_tokens: int = 4096,
    ) -> GenerationResult:
        try:
            response = await self.client.aio.models.generate_content(
                model=self.model,
                contents=user_prompt,
                config=types.GenerateContentConfig(
                    temperature=temperature,
                    max_output_tokens=max_tokens,
                    system_instruction=system_prompt,
                )
            )
            
            return GenerationResult(
                content=response.text,
                input_tokens=response.usage_metadata.prompt_token_count,
                output_tokens=response.usage_metadata.candidates_token_count,
                model=self.model,
                provider="gemini",
            )
        except Exception as e:
            logger.error(f"Gemini generation failed: {e}")
            raise
```

### Provider Implementation

from .base import AIProviderInterface, GenerationResult

logger = structlog.get_logger(**name**)

class GeminiProvider(AIProviderInterface):
    def **init**(self, api_key: str):
        self.client = genai.Client(api_key=api_key)
        self.model = "gemini-1.5-pro"

    async def generate_text(
        self,
        system_prompt: str,
        user_prompt: str,
        *,
        temperature: float = 0.7,
        max_tokens: int = 4096,
    ) -> GenerationResult:
        """
        Generuje text pomocÃ­ Gemini.
        """
        config = types.GenerateContentConfig(
            temperature=temperature,
            max_output_tokens=max_tokens,
            system_instruction=system_prompt,
        )
        
        response = await self.client.aio.models.generate_content(
            model=self.model,
            contents=user_prompt,
            config=config,
        )
        
        return GenerationResult(
            content=response.text,
            input_tokens=response.usage_metadata.prompt_token_count,
            output_tokens=response.usage_metadata.candidates_token_count,
            model=self.model,
            provider="gemini",
            raw_response=response,
        )
    
    async def generate_structured(
        self,
        system_prompt: str,
        user_prompt: str,
        response_schema: dict,
    ) -> GenerationResult:
        """
        Generuje strukturovanÃ½ JSON podle schema.
        """
        config = types.GenerateContentConfig(
            temperature=0.2,  # Lower for structured output
            system_instruction=system_prompt,
            response_mime_type="application/json",
            response_schema=response_schema,
        )
        
        response = await self.client.aio.models.generate_content(
            model=self.model,
            contents=user_prompt,
            config=config,
        )
        
        # Parse JSON response
        import json
        content = json.loads(response.text)
        
        return GenerationResult(
            content=content,
            input_tokens=response.usage_metadata.prompt_token_count,
            output_tokens=response.usage_metadata.candidates_token_count,
            model=self.model,
            provider="gemini",
            raw_response=response,
        )
    
    async def generate_stream(
        self,
        system_prompt: str,
        user_prompt: str,
        *,
        temperature: float = 0.7,
    ):
        """
        Streaming generovÃ¡nÃ­ pro real-time output.
        """
        config = types.GenerateContentConfig(
            temperature=temperature,
            system_instruction=system_prompt,
        )
        
        async for chunk in self.client.aio.models.generate_content_stream(
            model=self.model,
            contents=user_prompt,
            config=config,
        ):
            if chunk.text:
                yield chunk.text
    
    async def generate_embeddings(
        self,
        texts: list[str],
    ) -> list[list[float]]:
        """
        Generuje embeddings pro RAG.
        """
        embeddings = []
        for text in texts:
            response = await self.client.aio.models.embed_content(
                model="text-embedding-004",
                contents=text,
            )
            embeddings.append(response.embeddings[0].values)
        return embeddings

```

### Structured Output Schemas

```python
# apps/ai_gateway/schemas.py

PERSONA_SCHEMA = {
    "type": "object",
    "properties": {
        "personas": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "characterName": {"type": "string"},
                    "age": {"type": "integer"},
                    "roleInCompany": {"type": "string"},
                    "jungArchetype": {
                        "type": "string",
                        "enum": ["innocent", "everyman", "hero", "outlaw", "explorer", 
                                "creator", "ruler", "magician", "lover", "caregiver", 
                                "jester", "sage"]
                    },
                    "mbtiType": {
                        "type": "string",
                        "enum": ["INTJ", "INTP", "ENTJ", "ENTP", "INFJ", "INFP", 
                                "ENFJ", "ENFP", "ISTJ", "ISFJ", "ESTJ", "ESFJ",
                                "ISTP", "ISFP", "ESTP", "ESFP"]
                    },
                    "dominantValue": {"type": "string"},
                    "mainFrustration": {"type": "string"},
                    "neuroticismLevel": {"type": "string"},
                    "vocabularyLevel": {"type": "string"},
                    "sentencePreference": {"type": "string"},
                    "metaphorUsage": {"type": "string"},
                    "argumentStructure": {"type": "string"},
                    "favoritePhrasesKeywords": {"type": "string"},
                    "uniqueSignatureEnding": {"type": "string"},
                    "artStyleName": {"type": "string"},
                    "colorPalette": {"type": "string"},
                    "visualAtmosphere": {"type": "string"},
                    "backstoryHighlight": {"type": "string"},
                    "hobbyOutsideWork": {"type": "string"},
                },
                "required": ["characterName", "jungArchetype", "mbtiType"]
            }
        }
    },
    "required": ["personas"]
}

TOPICS_SCHEMA = {
    "type": "object",
    "properties": {
        "topics": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "title": {"type": "string"},
                    "subtitle": {"type": "string"},
                    "description": {"type": "string"},
                    "keywords": {"type": "array", "items": {"type": "string"}},
                    "focusKeyword": {"type": "string"},
                    "searchIntent": {"type": "string"},
                    "plannedDate": {"type": "string"},
                    "personaId": {"type": "string"},
                },
                "required": ["title", "description", "focusKeyword"]
            }
        }
    }
}

BLOGPOST_SCHEMA = {
    "type": "object",
    "properties": {
        "title": {"type": "string"},
        "slug": {"type": "string"},
        "metaTitle": {"type": "string"},
        "metaDescription": {"type": "string"},
        "sections": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "sectionType": {"type": "string"},
                    "heading": {"type": "string"},
                    "headingLevel": {"type": "integer"},
                    "content": {"type": "string"},
                    "hasImage": {"type": "boolean"},
                    "hasCta": {"type": "boolean"},
                }
            }
        },
        "faqs": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "question": {"type": "string"},
                    "answer": {"type": "string"},
                }
            }
        },
        "keyTakeaways": {"type": "array", "items": {"type": "string"}},
        "wordCount": {"type": "integer"},
    }
}
```

---

## 4. PERPLEXITY API

### Provider Implementation

```python
# apps/ai_gateway/providers/perplexity.py
import httpx
import structlog

from .base import GenerationResult

logger = structlog.get_logger(__name__)

class PerplexityProvider:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.perplexity.ai"
        self.model = "llama-3.1-sonar-large-128k-online"
    
    async def search(
        self,
        query: str,
        *,
        system_prompt: str | None = None,
    ) -> GenerationResult:
        """
        VyhledÃ¡vÃ¡ informace na webu.
        """
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.base_url}/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json",
                },
                json={
                    "model": self.model,
                    "messages": [
                        {
                            "role": "system",
                            "content": system_prompt or "Be precise and concise."
                        },
                        {
                            "role": "user",
                            "content": query
                        }
                    ],
                },
                timeout=60.0,
            )
            response.raise_for_status()
            data = response.json()
        
        return GenerationResult(
            content=data["choices"][0]["message"]["content"],
            input_tokens=data.get("usage", {}).get("prompt_tokens", 0),
            output_tokens=data.get("usage", {}).get("completion_tokens", 0),
            model=self.model,
            provider="perplexity",
            raw_response=data,
        )
    
    async def scrape_company(
        self,
        company_name: str,
        website: str | None = None,
    ) -> dict:
        """
        Scrapuje informace o firmÄ› pro Company DNA.
        """
        query = f"""
        Najdi detailnÃ­ informace o firmÄ› "{company_name}":
        1. Obor podnikÃ¡nÃ­ a hlavnÃ­ produkty/sluÅ¾by
        2. CÃ­lovÃ¡ skupina zÃ¡kaznÃ­kÅ¯
        3. HlavnÃ­ konkurenti
        4. Tone of voice a styl komunikace
        5. UnikÃ¡tnÃ­ prodejnÃ­ argumenty (USP)
        6. Historie a zajÃ­mavosti
        
        {"Website: " + website if website else ""}
        
        OdpovÄ›z strukturovanÄ› v JSON formÃ¡tu.
        """
        
        result = await self.search(
            query,
            system_prompt="Jsi expert na analÃ½zu firem. OdpovÃ­dej v JSON formÃ¡tu."
        )
        
        # Parse response
        import json
        try:
            return json.loads(result.content)
        except json.JSONDecodeError:
## 4. PERPLEXITY API

### Provider Implementation

```python
# apps/ai_gateway/providers/perplexity.py
import httpx
import structlog

from .base import GenerationResult

logger = structlog.get_logger(__name__)

class PerplexityProvider:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.perplexity.ai"
        self.model = "llama-3.1-sonar-large-128k-online"
    
    async def search(
        self,
        query: str,
        *,
        system_prompt: str | None = None,
    ) -> GenerationResult:
        """
        VyhledÃ¡vÃ¡ informace na webu.
        """
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.base_url}/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json",
                },
                json={
                    "model": self.model,
                    "messages": [
                        {
                            "role": "system",
                            "content": system_prompt or "Be precise and concise."
                        },
                        {
                            "role": "user",
                            "content": query
                        }
                    ],
                },
                timeout=60.0,
            )
            response.raise_for_status()
            data = response.json()
        
        return GenerationResult(
            content=data["choices"][0]["message"]["content"],
            input_tokens=data.get("usage", {}).get("prompt_tokens", 0),
            output_tokens=data.get("usage", {}).get("completion_tokens", 0),
            model=self.model,
            provider="perplexity",
            raw_response=data,
        )
    
    async def scrape_company(
        self,
        company_name: str,
        website: str | None = None,
    ) -> dict:
        """
        Scrapuje informace o firmÄ› pro Company DNA.
        """
        query = f"""
        Najdi detailnÃ­ informace o firmÄ› "{company_name}":
        1. Obor podnikÃ¡nÃ­ a hlavnÃ­ produkty/sluÅ¾by
        2. CÃ­lovÃ¡ skupina zÃ¡kaznÃ­kÅ¯
        3. HlavnÃ­ konkurenti
        4. Tone of voice a styl komunikace
        5. UnikÃ¡tnÃ­ prodejnÃ­ argumenty (USP)
        6. Historie a zajÃ­mavosti
        
        {"Website: " + website if website else ""}
        
        OdpovÄ›z strukturovanÄ› v JSON formÃ¡tu.
        """
        
        result = await self.search(
            query,
            system_prompt="Jsi expert na analÃ½zu firem. OdpovÃ­dej v JSON formÃ¡tu."
        )
        
        # Parse response
        import json
        try:
            return json.loads(result.content)
        except json.JSONDecodeError:
            return {"raw_info": result.content}
```

**AktuÃ¡lnÃ­ stav implementace:**

- âœ… **PerplexityProvider existuje** - ImplementovÃ¡n v `providers/perplexity.py`
- âœ… **API KEY** - `PERPLEXITY_API_KEY` je sprÃ¡vnÄ› nakonfigurovÃ¡n v `.env`
- âœ… **`search()` metoda** - Funguje a pouÅ¾Ã­vÃ¡ se pro web search a research
- âœ… **`scrape_company()` metoda** - **TOTO JE KLÃÄŒOVÃ FUNKCE** - pouÅ¾Ã­vÃ¡ se v `scrape_company_dna()` pro zÃ­skÃ¡vÃ¡nÃ­ informacÃ­ o firmÃ¡ch
- âŒ **`structlog`** - NenÃ­ pouÅ¾it, mÃ­sto toho standardnÃ­ Python `logging`
- âœ… **HTTP komunikace** - PouÅ¾Ã­vÃ¡ `httpx.AsyncClient` pro async poÅ¾adavky
- âœ… **Model**: PouÅ¾Ã­vÃ¡ `llama-3.1-sonar-large-128k-online` nebo podobnÃ½ online model
- âœ… **Timeout handling** - MÃ¡ nastavenÃ½ 60s timeout
- âš ï¸ **Error handling** - ZÃ¡kladnÃ­ `raise_for_status()`, moÅ¾nÃ¡ chybÃ­ retry logika

**SkuteÄnÃ© pouÅ¾itÃ­ v aplikaci:**

```python
# Funkce scrape_company_dna() pouÅ¾Ã­vÃ¡ PerplexityProvider:
async def scrape_company_dna(domain: str, organization_id: str):
    provider = get_research_provider()  # VracÃ­ PerplexityProvider
    
    # VyhledÃ¡ informace o firmÄ›
    query = f"detailnÃ­ informace o firmÄ› s domÃ©nou {domain}"
    result = await provider.search(query=query)
    
    # AlternativnÄ› mÅ¯Å¾e volat pÅ™Ã­mo scrape_company():
    # company_info = await provider.scrape_company(
    #     company_name="Firma s.r.o.",
    #     website=domain
    # )
    
    return result.content
```

---

## 5. IMAGE GENERATION (NANOBANA)

### Provider Implementation

```python
# apps/ai_gateway/providers/nanobana.py
import httpx
import structlog

from .base import ImageProviderInterface, ImageResult

logger = structlog.get_logger(__name__)

class NanobanaProvider(ImageProviderInterface):
    """
    Nanobana Pro provider (Imagen 3).
    """
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.nanobana.ai"
    
    async def generate_image(
        self,
        prompt: str,
        *,
        aspect_ratio: str = "1:1",
        style: str | None = None,
        negative_prompt: str | None = None,
    ) -> ImageResult:
        """
        Generuje obrÃ¡zek pomocÃ­ Imagen 3.
        """
        # Build full prompt
        full_prompt = prompt
        if style:
            full_prompt = f"{prompt}, {style} style"
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.base_url}/v1/images/generate",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json",
                },
                json={
                    "prompt": full_prompt,
                    "negative_prompt": negative_prompt or "blurry, low quality, distorted",
                    "aspect_ratio": aspect_ratio,
                    "model": "imagen-3",
                    "output_format": "png",
                },
                timeout=120.0,
            )
            response.raise_for_status()
            data = response.json()
        
## 5. IMAGE GENERATION (NANOBANA)

### Provider Implementation

```python
# apps/ai_gateway/providers/nanobana.py
import httpx
import structlog

from .base import ImageProviderInterface, ImageResult

logger = structlog.get_logger(__name__)

class NanobanaProvider(ImageProviderInterface):
    """
    Nanobana Pro provider (Imagen 3).
    """
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.nanobana.ai"
    
    async def generate_image(
        self,
        prompt: str,
        *,
        aspect_ratio: str = "1:1",
        style: str | None = None,
        negative_prompt: str | None = None,
    ) -> ImageResult:
        """
        Generuje obrÃ¡zek pomocÃ­ Imagen 3.
        """
        # Build full prompt
        full_prompt = prompt
        if style:
            full_prompt = f"{prompt}, {style} style"
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.base_url}/v1/images/generate",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json",
                },
                json={
                    "prompt": full_prompt,
                    "negative_prompt": negative_prompt or "blurry, low quality, distorted",
                    "aspect_ratio": aspect_ratio,
                    "model": "imagen-3",
                    "output_format": "png",
                },
                timeout=120.0,
            )
            response.raise_for_status()
            data = response.json()
        
        return ImageResult(
            url=data["images"][0]["url"],
            prompt_used=full_prompt,
            model="imagen-3",
            provider="nanobana",
        )
```

**AktuÃ¡lnÃ­ stav implementace:**

- âŒ **NanobanaProvider NEEXISTUJE** - NenÃ­ implementovÃ¡n, image generation zatÃ­m nenÃ­ aktivnÃ­ feature
- âœ… **API KEY existuje** - `NANOBANA_API_KEY` je v `.env`, ale provider nenÃ­ spuÅ¡tÄ›nÃ½
- âŒ **`ImageResult` dataclass** - NenÃ­ implementovÃ¡na
- âŒ **`ImageProviderInterface`** - NenÃ­ implementovÃ¡na
- âŒ **Integrace s Nanobana API** - NenÃ­ implementovÃ¡na
- âš ï¸ **PlÃ¡novanÃ¡ feature** - Image generation je na roadmapÄ› pro PRO+ tier

**Status:**

```
ðŸ”´ NENÃ IMPLEMENTOVÃNO
ðŸ“‹ PlÃ¡novÃ¡no pro budoucÃ­ verzi
ðŸ’° SouÄÃ¡st PRO+ subscription tier
```

Image generation je komplexnÃ­ feature, kterÃ¡ vyÅ¾aduje:

1. Implementaci NanobanaProvider
2. Image storage (S3/Cloudinary)
3. Feature gating podle subscription tier
4. UI pro image generation
5. Cost tracking pro images

### Visual Prompt Engineering

```python
# apps/ai_gateway/visual_prompt.py

class VisualPromptEngineer:
    """
    Generuje optimalizovanÃ© prompty pro image generation.
    Implementuje "Authenticity Trend 2026" logiku.
    """
    
    # Industry -> Authenticity fit mapping
    HIGH_AUTHENTICITY_INDUSTRIES = [
        'personal_brand', 'small_business', 'local', 'nonprofit',
        'fitness', 'creative', 'eco', 'startup', 'community'
    ]
    
    LOW_AUTHENTICITY_INDUSTRIES = [
        'luxury', 'finance', 'legal', 'healthcare', 'corporate',
        'real_estate', 'enterprise'
    ]
    
    PLATFORM_ASPECTS = {
        'instagram_feed': '1:1',
        'instagram_story': '9:16',
        'facebook_feed': '16:9',
        'linkedin': '16:9',
        'tiktok': '9:16',
        'twitter': '16:9',
        'pinterest': '2:3',
    }
    
