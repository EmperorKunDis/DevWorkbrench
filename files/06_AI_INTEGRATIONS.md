# 06_AI_INTEGRATIONS.md - Kompletn√≠ AI Integrace

**Dokument:** AI Integrations pro PostHub.work  
**Verze:** 1.0.0  
**Status:** Production-Ready  
**Self-Contained:** ‚úÖ Tento dokument obsahuje V≈†ECHNY informace o AI integrac√≠ch

---

## üìã OBSAH

1. [P≈ôehled](#1-p≈ôehled)
2. [AI Gateway Architecture](#2-ai-gateway-architecture)
3. [Google Gemini](#3-google-gemini)
4. [Perplexity API](#4-perplexity-api)
5. [Image Generation (Nanobana)](#5-image-generation-nanobana)
6. [Video Generation (Veo 3)](#6-video-generation-veo-3)
7. [Prompt Engineering](#7-prompt-engineering)
8. [Cost Tracking](#8-cost-tracking)
9. [Caching & Optimization](#9-caching--optimization)

---

## 1. P≈òEHLED

### AI Provider Stack

| Provider | Purpose | Tier Access |
|----------|---------|-------------|
| Google Gemini 1.5 Pro | Text generation, logic | ALL |
| Perplexity API | Web search, scraping | ALL |
| Nanobana Pro (Imagen 3) | Image generation | PRO+ |
| Veo 3 | Video generation | ULTIMATE |

### Dependencies

```txt
# requirements/base.txt
google-genai>=1.0.0      # NEW Gemini SDK
litellm>=1.50.0          # Multi-provider gateway
tiktoken>=0.7.0          # Token counting
httpx>=0.27.0            # Async HTTP
jinja2>=3.1.0            # Prompt templates
```

**Aktu√°ln√≠ stav implementace:**
- ‚úÖ `google-genai>=1.0.0` - Je nainstalov√°no a aktivnƒõ pou≈æ√≠v√° se v GeminiProvider
- ‚ùå `litellm>=1.50.0` - Je v requirements, ale v k√≥du je **zakomentovan√©** (nen√≠ aktivnƒõ pou≈æ√≠v√°no)
- ‚ùå `tiktoken>=0.7.0` - Nen√≠ v aktu√°ln√≠ch requirements
- ‚úÖ `httpx>=0.27.0` - Je nainstalov√°no a pou≈æ√≠v√° se pro HTTP komunikaci
- ‚úÖ `jinja2>=3.1.0` - Je nainstalov√°no (pou≈æ√≠v√° se pro templating v promptech)
- ‚ö†Ô∏è Realita pou≈æ√≠v√° standardn√≠ Python `logging` nam√≠sto `structlog`, jak je uvedeno v pl√°novan√©m k√≥du n√≠≈æe

---

## 2. AI GATEWAY ARCHITECTURE

### Gateway Pattern

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          AI GATEWAY                                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                    AIGateway Service                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Unified interface for all providers                       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Automatic retries & fallbacks                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Cost tracking per tenant                                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Rate limiting                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                               ‚îÇ                                      ‚îÇ
‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ         ‚îÇ                     ‚îÇ                     ‚îÇ               ‚îÇ
‚îÇ         ‚ñº                     ‚ñº                     ‚ñº               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ   Gemini    ‚îÇ      ‚îÇ Perplexity  ‚îÇ      ‚îÇ  Nanobana   ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  Provider   ‚îÇ      ‚îÇ  Provider   ‚îÇ      ‚îÇ  Provider   ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Aktu√°ln√≠ stav implementace:**
- ‚ùå **Centr√°ln√≠ `AIGateway` t≈ô√≠da neexistuje** - m√≠sto OOP Gateway Pattern pou≈æ√≠v√° k√≥d **funkcion√°ln√≠ factory pattern**
- ‚úÖ **Provider t≈ô√≠dy existuj√≠** - `GeminiProvider`, `PerplexityProvider` jsou implementov√°ny
- ‚ùå **NanobanaProvider** - Nen√≠ je≈°tƒõ implementov√°n (Nanobana integrace pl√°nov√°na)
- ‚ùå **Unified interface** - Neexistuje centr√°ln√≠ bod vol√°n√≠, m√≠sto toho se pou≈æ√≠vaj√≠ factory funkce:
  - `get_text_provider()` - vrac√≠ GeminiProvider
  - `get_research_provider()` - vrac√≠ PerplexityProvider  
- ‚ùå **Automatic retries & fallbacks** - Nen√≠ implementov√°no na gateway √∫rovni
- ‚ùå **Cost tracking per tenant** - CostTracker t≈ô√≠da nen√≠ implementov√°na
- ‚ùå **Rate limiting** - Nen√≠ implementov√°no na gateway √∫rovni

**Skuteƒçn√° architektura:**
```python
# providers/__init__.py
def get_text_provider() -> AIProvider:
    return GeminiProvider()

def get_research_provider() -> AIProvider:
    return PerplexityProvider()

# Pou≈æit√≠ v k√≥du:
provider = get_research_provider()
result = await provider.search(query)
```

M√≠sto centralizovan√© gateway t≈ô√≠dy, k√≥d pou≈æ√≠v√° **factory funkce** pro z√≠sk√°n√≠ jednotliv√Ωch provider≈Ø. Ka≈æd√Ω provider se pou≈æ√≠v√° p≈ô√≠mo tam, kde je pot≈ôeba.

### Base Provider Interface

```python
# apps/ai_gateway/providers/base.py
from abc import ABC, abstractmethod
from typing import Any
from dataclasses import dataclass

@dataclass
class GenerationResult:
    content: str | dict
    input_tokens: int
    output_tokens: int
    model: str
    provider: str
    raw_response: Any = None

@dataclass  
class ImageResult:
    url: str
    prompt_used: str
    model: str
    provider: str

class AIProviderInterface(ABC):
    @abstractmethod
    async def generate_text(
        self,
        system_prompt: str,
        user_prompt: str,
        *,
        temperature: float = 0.7,
        max_tokens: int = 4096,
    ) -> GenerationResult:
        pass
    
    @abstractmethod
    async def generate_structured(
        self,
        system_prompt: str,
        user_prompt: str,
        response_schema: dict,
    ) -> GenerationResult:
        pass

### Base Provider Interface

```python
# apps/ai_gateway/providers/base.py
from abc import ABC, abstractmethod
from typing import Any
from dataclasses import dataclass

@dataclass
class GenerationResult:
    content: str | dict
    input_tokens: int
    output_tokens: int
    model: str
    provider: str
    raw_response: Any = None

@dataclass  
class ImageResult:
    url: str
    prompt_used: str
    model: str
    provider: str

class AIProviderInterface(ABC):
    @abstractmethod
    async def generate_text(
        self,
        system_prompt: str,
        user_prompt: str,
        *,
        temperature: float = 0.7,
        max_tokens: int = 4096,
    ) -> GenerationResult:
        pass
    
    @abstractmethod
    async def generate_structured(
        self,
        system_prompt: str,
        user_prompt: str,
        response_schema: dict,
    ) -> GenerationResult:
        pass

### Base Provider Interface

```python
# apps/ai_gateway/providers/base.py
from abc import ABC, abstractmethod
from typing import Any
from dataclasses import dataclass

@dataclass
class GenerationResult:
    content: str | dict
    input_tokens: int
    output_tokens: int
    model: str
    provider: str
    raw_response: Any = None

@dataclass  
class ImageResult:
    url: str
    prompt_used: str
    model: str
    provider: str

class AIProviderInterface(ABC):
    @abstractmethod
    async def generate_text(
        self,
        system_prompt: str,
        user_prompt: str,
        *,
        temperature: float = 0.7,
        max_tokens: int = 4096,
    ) -> GenerationResult:
        pass
    
    @abstractmethod
    async def generate_structured(
        self,
        system_prompt: str,
        user_prompt: str,
        response_schema: dict,
    ) -> GenerationResult:
        pass

class ImageProviderInterface(ABC):
    @abstractmethod
    async def generate_image(
        self,
        prompt: str,
        *,
        aspect_ratio: str = "1:1",
        style: str | None = None,
    ) -> ImageResult:
        pass
```

**Aktu√°ln√≠ stav implementace:**
- ‚úÖ **Base provider interface existuje** - `AIProvider` abstraktn√≠ t≈ô√≠da je definov√°na v `providers/base.py` (4,686 byt≈Ø)
- ‚úÖ **`GenerationResult` dataclass** - Existuje a pou≈æ√≠v√° se pro n√°vratov√© hodnoty
- ‚ùå **`ImageResult` dataclass** - Nen√≠ implementov√°na (image generation zat√≠m nen√≠ aktivn√≠)
- ‚úÖ **`AIProviderInterface`** - Implementov√°na jako `AIProvider` abstraktn√≠ t≈ô√≠da

**Skuteƒçn√© soubory v `providers/` slo≈æce:**
```bash
providers/
‚îú‚îÄ‚îÄ __init__.py          (476 byt≈Ø)   - Factory funkce get_text_provider(), get_research_provider()
‚îú‚îÄ‚îÄ base.py              (4,686 byt≈Ø) - AIProvider abstraktn√≠ t≈ô√≠da, GenerationResult dataclass
‚îú‚îÄ‚îÄ gemini.py            (4,364 byt≈Ø) - GeminiProvider implementace
‚îî‚îÄ‚îÄ perplexity.py        (5,842 byt≈Ø) - PerplexityProvider implementace
```

**Skuteƒçn√° implementace v `base.py`:**
```python
# providers/base.py (skuteƒçn√Ω k√≥d)
from abc import ABC, abstractmethod
from dataclasses import dataclass

@dataclass
class GenerationResult:
    content: str | dict
    input_tokens: int
    output_tokens: int
    model: str
    provider: str
    raw_response: Any = None

class AIProvider(ABC):
    """Base class for all AI providers."""
    
    @abstractmethod
    def generate_text(self, prompt: str, **kwargs) -> GenerationResult:
        """Generate text from prompt."""
        pass
    
    @abstractmethod
    def generate_json(self, prompt: str, schema: dict) -> dict:
        """Generate structured JSON output."""
        pass
```

**Factory funkce v `__init__.py`:**
```python
# providers/__init__.py (skuteƒçn√Ω k√≥d)
def get_text_provider() -> AIProvider:
    """Get the default text generation provider (Gemini)."""
    return GeminiProvider()

def get_research_provider() -> AIProvider:
    """Get the web research provider (Perplexity)."""
    return PerplexityProvider()
```

### AI Gateway Service

```python
# apps/ai_gateway/services.py
import structlog
from django.conf import settings
from jinja2 import Template

from apps.ai_gateway.providers.gemini import GeminiProvider
from apps.ai_gateway.providers.perplexity import PerplexityProvider
from apps.ai_gateway.providers.nanobana import NanobanaProvider
from apps.ai_gateway.models import PromptTemplate, GenerationJob
from apps.ai_gateway.cost_tracker import CostTracker

logger = structlog.get_logger(__name__)

class AIGateway:
    def __init__(self):
        self.gemini = GeminiProvider(api_key=settings.GEMINI_API_KEY)
        self.perplexity = PerplexityProvider(api_key=settings.PERPLEXITY_API_KEY)
        self.nanobana = NanobanaProvider(api_key=settings.NANOBANA_API_KEY)
        self.cost_tracker = CostTracker()
    
    async def generate(
        self,
        prompt_template: PromptTemplate,
        variables: dict,
        organization,
    ) -> GenerationResult:
        """
        Generuje text pomoc√≠ Gemini s template.
        """
        # Render prompts
        system_prompt = prompt_template.system_prompt
        user_prompt = Template(prompt_template.user_prompt_template).render(**variables)
        
        logger.info(
            "ai_generate_start",
            template=prompt_template.code,
            org_id=str(organization.id),
        )
        
        # Generate
        result = await self.gemini.generate_text(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            temperature=float(prompt_template.temperature),
            max_tokens=prompt_template.max_tokens,
        )
        
        # Track cost
        await self.cost_tracker.track(
            organization=organization,
            provider='gemini',
            input_tokens=result.input_tokens,
            output_tokens=result.output_tokens,
        )
        
        logger.info(
            "ai_generate_complete",
            template=prompt_template.code,
            input_tokens=result.input_tokens,
            output_tokens=result.output_tokens,
        )
        
        return result
    
    async def generate_structured(
        self,
        prompt_template: PromptTemplate,
        variables: dict,
        response_schema: dict,
        organization,
    ) -> GenerationResult:
        """
        Generuje strukturovan√Ω JSON output.
        """
        system_prompt = prompt_template.system_prompt
        user_prompt = Template(prompt_template.user_prompt_template).render(**variables)
        
        result = await self.gemini.generate_structured(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            response_schema=response_schema,
        )
        
        await self.cost_tracker.track(
            organization=organization,
            provider='gemini',
            input_tokens=result.input_tokens,
            output_tokens=result.output_tokens,
        )
        
        return result
    
    async def search_web(
        self,
        query: str,
        organization,
    ) -> str:
        """
        Vyhled√°v√° informace pomoc√≠ Perplexity.
        """
        result = await self.perplexity.search(query)
        
        await self.cost_tracker.track(
            organization=organization,
            provider='perplexity',
            input_tokens=result.input_tokens,
            output_tokens=result.output_tokens,
        )
        
        return result.content
    
    async def generate_image(
        self,
        prompt: str,
        organization,
        *,
        aspect_ratio: str = "1:1",
    ) -> ImageResult:
        """
        Generuje obr√°zek pomoc√≠ Nanobana/Imagen.
        """
        # Check feature access
        if not organization.has_feature('image_generation'):
            raise PermissionError("Image generation requires PRO subscription")
        
        result = await self.nanobana.generate_image(
            prompt=prompt,
            aspect_ratio=aspect_ratio,
        )
        
        await self.cost_tracker.track_image(
            organization=organization,
            provider='nanobana',
        )
        
### AI Gateway Service

```python
# apps/ai_gateway/services.py
import structlog
from django.conf import settings
from jinja2 import Template

from apps.ai_gateway.providers.gemini import GeminiProvider
from apps.ai_gateway.providers.perplexity import PerplexityProvider
from apps.ai_gateway.providers.nanobana import NanobanaProvider
from apps.ai_gateway.models import PromptTemplate, GenerationJob
from apps.ai_gateway.cost_tracker import CostTracker

logger = structlog.get_logger(__name__)

class AIGateway:
    def __init__(self):
        self.gemini = GeminiProvider(api_key=settings.GEMINI_API_KEY)
        self.perplexity = PerplexityProvider(api_key=settings.PERPLEXITY_API_KEY)
        self.nanobana = NanobanaProvider(api_key=settings.NANOBANA_API_KEY)
        self.cost_tracker = CostTracker()
    
    async def generate(
        self,
        prompt_template: PromptTemplate,
        variables: dict,
        organization,
    ) -> GenerationResult:
        """
        Generuje text pomoc√≠ Gemini s template.
        """
        # Render prompts
        system_prompt = prompt_template.system_prompt
        user_prompt = Template(prompt_template.user_prompt_template).render(**variables)
        
        logger.info(
            "ai_generate_start",
            template=prompt_template.code,
            org_id=str(organization.id),
        )
        
        # Generate
        result = await self.gemini.generate_text(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            temperature=float(prompt_template.temperature),
            max_tokens=prompt_template.max_tokens,
        )
        
        # Track cost
        await self.cost_tracker.track(
            organization=organization,
            provider='gemini',
            input_tokens=result.input_tokens,
            output_tokens=result.output_tokens,
        )
        
        logger.info(
            "ai_generate_complete",
            template=prompt_template.code,
            input_tokens=result.input_tokens,
            output_tokens=result.output_tokens,
        )
        
        return result
    
    async def generate_structured(
        self,
        prompt_template: PromptTemplate,
        variables: dict,
        response_schema: dict,
        organization,
    ) -> GenerationResult:
        """
        Generuje strukturovan√Ω JSON output.
        """
        system_prompt = prompt_template.system_prompt
        user_prompt = Template(prompt_template.user_prompt_template).render(**variables)
        
        result = await self.gemini.generate_structured(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            response_schema=response_schema,
        )
        
        await self.cost_tracker.track(
            organization=organization,
            provider='gemini',
            input_tokens=result.input_tokens,
            output_tokens=result.output_tokens,
        )
        
        return result
    
    async def search_web(
        self,
        query: str,
        organization,
    ) -> str:
        """
        Vyhled√°v√° informace pomoc√≠ Perplexity.
        """
        result = await self.perplexity.search(query)
        
        await self.cost_tracker.track(
            organization=organization,
            provider='perplexity',
            input_tokens=result.input_tokens,
            output_tokens=result.output_tokens,
        )
        
        return result.content
    
    async def generate_image(
        self,
        prompt: str,
        organization,
        *,
        aspect_ratio: str = "1:1",
    ) -> ImageResult:
        """
        Generuje obr√°zek pomoc√≠ Nanobana/Imagen.
        """
        # Check feature access
        if not organization.has_feature('image_generation'):
            raise PermissionError("Image generation requires PRO subscription")
        
        result = await self.nanobana.generate_image(
            prompt=prompt,
            aspect_ratio=aspect_ratio,
        )
        
        await self.cost_tracker.track_image(
            organization=organization,
            provider='nanobana',
        )
        
        return result
```

**Aktu√°ln√≠ stav implementace:**
- ‚ùå **`AIGateway` t≈ô√≠da NEEXISTUJE** - cel√° tato centr√°ln√≠ slu≈æba nen√≠ implementov√°na
- ‚ùå **`structlog`** - Nen√≠ pou≈æit, m√≠sto toho standardn√≠ Python `logging`
- ‚ùå **`PromptTemplate` model** - DB model pro ≈°ablony pravdƒõpodobnƒõ neexistuje, prompty jsou hardcoded
- ‚ùå **`CostTracker` t≈ô√≠da** - Nen√≠ implementov√°na
- ‚ùå **Template rendering s Jinja2** - Nen√≠ pou≈æito, prompty jsou pravdƒõpodobnƒõ hardcoded stringy
- ‚ùå **Cost tracking** - Nen√≠ implementov√°no sledov√°n√≠ n√°klad≈Ø na √∫rovni organizace
- ‚ùå **Feature gating** (`organization.has_feature()`) - Nen√≠ implementov√°no

**Skuteƒçn√° implementace:**
```python
# M√≠sto AIGateway t≈ô√≠dy existuj√≠ pouze factory funkce:

def get_text_provider() -> AIProvider:
    """Vrac√≠ Gemini provider pro text generov√°n√≠."""
    return GeminiProvider()

def get_research_provider() -> AIProvider:
    """Vrac√≠ Perplexity provider pro research."""
    return PerplexityProvider()

# Pou≈æit√≠ p≈ô√≠mo v k√≥du:
async def scrape_company_dna(domain: str, organization_id: str):
    provider = get_research_provider()
    result = await provider.search(query=f"company information {domain}")
    return result.content
```

K√≥d pou≈æ√≠v√° **funkcion√°ln√≠ p≈ô√≠stup** s p≈ô√≠m√Ωm vol√°n√≠m provider≈Ø, ne centralizovanou OOP gateway t≈ô√≠du s cost trackingem a template managementem.

---

## 3. GOOGLE GEMINI

### Provider Implementation

```python
# apps/ai_gateway/providers/gemini.py
import google.genai as genai
from google.genai import types
import structlog

**Aktu√°ln√≠ stav implementace:**
- ‚úÖ **GeminiProvider existuje** - Implementov√°n v `providers/gemini.py`
- ‚úÖ **Pou≈æ√≠v√° `google.genai`** - Nov√© Google Gemini SDK je aktivnƒõ pou≈æ√≠v√°no
- ‚úÖ **API KEY** - `GEMINI_API_KEY` je spr√°vnƒõ nakonfigurov√°n v `.env`
- ‚ùå **`structlog`** - Nen√≠ pou≈æit, m√≠sto toho standardn√≠ Python `logging`
- ‚úÖ **`generate_text()` metoda** - Funguje a pou≈æ√≠v√° se pro text generov√°n√≠
- ‚úÖ **`generate_structured()` metoda** - M≈Ø≈æe existovat pro JSON output
- ‚úÖ **Model**: Pou≈æ√≠v√° `gemini-1.5-pro-002` nebo podobn√Ω model
- ‚ùå **Error handling** - Z√°kladn√≠ try/catch m≈Ø≈æe chybƒõt robustn√≠ retry logika
- ‚ùå **Token counting** - Pravdƒõpodobnƒõ nen√≠ p≈ôesn√© poƒç√≠t√°n√≠ token≈Ø (chyb√≠ `tiktoken`)

**Skuteƒçn√° implementace vypad√° p≈ôibli≈ænƒõ takto:**
```python
# providers/gemini.py
import logging
import google.genai as genai
from google.genai import types

logger = logging.getLogger(__name__)

class GeminiProvider:
    def __init__(self):
        self.client = genai.Client(api_key=settings.GEMINI_API_KEY)
        self.model = "gemini-1.5-pro-002"
    
    async def generate_text(
        self,
        system_prompt: str,
        user_prompt: str,
        temperature: float = 0.7,
        max_tokens: int = 4096,
    ) -> GenerationResult:
        try:
            response = await self.client.aio.models.generate_content(
                model=self.model,
                contents=user_prompt,
                config=types.GenerateContentConfig(
                    temperature=temperature,
                    max_output_tokens=max_tokens,
                    system_instruction=system_prompt,
                )
            )
            
            return GenerationResult(
                content=response.text,
                input_tokens=response.usage_metadata.prompt_token_count,
                output_tokens=response.usage_metadata.candidates_token_count,
                model=self.model,
                provider="gemini",
            )
        except Exception as e:
            logger.error(f"Gemini generation failed: {e}")
            raise
```

### Provider Implementation

from .base import AIProviderInterface, GenerationResult

logger = structlog.get_logger(__name__)

class GeminiProvider(AIProviderInterface):
    def __init__(self, api_key: str):
        self.client = genai.Client(api_key=api_key)
        self.model = "gemini-1.5-pro"
    
    async def generate_text(
        self,
        system_prompt: str,
        user_prompt: str,
        *,
        temperature: float = 0.7,
        max_tokens: int = 4096,
    ) -> GenerationResult:
        """
        Generuje text pomoc√≠ Gemini.
        """
        config = types.GenerateContentConfig(
            temperature=temperature,
            max_output_tokens=max_tokens,
            system_instruction=system_prompt,
        )
        
        response = await self.client.aio.models.generate_content(
            model=self.model,
            contents=user_prompt,
            config=config,
        )
        
        return GenerationResult(
            content=response.text,
            input_tokens=response.usage_metadata.prompt_token_count,
            output_tokens=response.usage_metadata.candidates_token_count,
            model=self.model,
            provider="gemini",
            raw_response=response,
        )
    
    async def generate_structured(
        self,
        system_prompt: str,
        user_prompt: str,
        response_schema: dict,
    ) -> GenerationResult:
        """
        Generuje strukturovan√Ω JSON podle schema.
        """
        config = types.GenerateContentConfig(
            temperature=0.2,  # Lower for structured output
            system_instruction=system_prompt,
            response_mime_type="application/json",
            response_schema=response_schema,
        )
        
        response = await self.client.aio.models.generate_content(
            model=self.model,
            contents=user_prompt,
            config=config,
        )
        
        # Parse JSON response
        import json
        content = json.loads(response.text)
        
        return GenerationResult(
            content=content,
            input_tokens=response.usage_metadata.prompt_token_count,
            output_tokens=response.usage_metadata.candidates_token_count,
            model=self.model,
            provider="gemini",
            raw_response=response,
        )
    
    async def generate_stream(
        self,
        system_prompt: str,
        user_prompt: str,
        *,
        temperature: float = 0.7,
    ):
        """
        Streaming generov√°n√≠ pro real-time output.
        """
        config = types.GenerateContentConfig(
            temperature=temperature,
            system_instruction=system_prompt,
        )
        
        async for chunk in self.client.aio.models.generate_content_stream(
            model=self.model,
            contents=user_prompt,
            config=config,
        ):
            if chunk.text:
                yield chunk.text
    
    async def generate_embeddings(
        self,
        texts: list[str],
    ) -> list[list[float]]:
        """
        Generuje embeddings pro RAG.
        """
        embeddings = []
        for text in texts:
            response = await self.client.aio.models.embed_content(
                model="text-embedding-004",
                contents=text,
            )
            embeddings.append(response.embeddings[0].values)
        return embeddings
```

### Structured Output Schemas

```python
# apps/ai_gateway/schemas.py

PERSONA_SCHEMA = {
    "type": "object",
    "properties": {
        "personas": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "characterName": {"type": "string"},
                    "age": {"type": "integer"},
                    "roleInCompany": {"type": "string"},
                    "jungArchetype": {
                        "type": "string",
                        "enum": ["innocent", "everyman", "hero", "outlaw", "explorer", 
                                "creator", "ruler", "magician", "lover", "caregiver", 
                                "jester", "sage"]
                    },
                    "mbtiType": {
                        "type": "string",
                        "enum": ["INTJ", "INTP", "ENTJ", "ENTP", "INFJ", "INFP", 
                                "ENFJ", "ENFP", "ISTJ", "ISFJ", "ESTJ", "ESFJ",
                                "ISTP", "ISFP", "ESTP", "ESFP"]
                    },
                    "dominantValue": {"type": "string"},
                    "mainFrustration": {"type": "string"},
                    "neuroticismLevel": {"type": "string"},
                    "vocabularyLevel": {"type": "string"},
                    "sentencePreference": {"type": "string"},
                    "metaphorUsage": {"type": "string"},
                    "argumentStructure": {"type": "string"},
                    "favoritePhrasesKeywords": {"type": "string"},
                    "uniqueSignatureEnding": {"type": "string"},
                    "artStyleName": {"type": "string"},
                    "colorPalette": {"type": "string"},
                    "visualAtmosphere": {"type": "string"},
                    "backstoryHighlight": {"type": "string"},
                    "hobbyOutsideWork": {"type": "string"},
                },
                "required": ["characterName", "jungArchetype", "mbtiType"]
            }
        }
    },
    "required": ["personas"]
}

TOPICS_SCHEMA = {
    "type": "object",
    "properties": {
        "topics": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "title": {"type": "string"},
                    "subtitle": {"type": "string"},
                    "description": {"type": "string"},
                    "keywords": {"type": "array", "items": {"type": "string"}},
                    "focusKeyword": {"type": "string"},
                    "searchIntent": {"type": "string"},
                    "plannedDate": {"type": "string"},
                    "personaId": {"type": "string"},
                },
                "required": ["title", "description", "focusKeyword"]
            }
        }
    }
}

BLOGPOST_SCHEMA = {
    "type": "object",
    "properties": {
        "title": {"type": "string"},
        "slug": {"type": "string"},
        "metaTitle": {"type": "string"},
        "metaDescription": {"type": "string"},
        "sections": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "sectionType": {"type": "string"},
                    "heading": {"type": "string"},
                    "headingLevel": {"type": "integer"},
                    "content": {"type": "string"},
                    "hasImage": {"type": "boolean"},
                    "hasCta": {"type": "boolean"},
                }
            }
        },
        "faqs": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "question": {"type": "string"},
                    "answer": {"type": "string"},
                }
            }
        },
        "keyTakeaways": {"type": "array", "items": {"type": "string"}},
        "wordCount": {"type": "integer"},
    }
}
```

---

## 4. PERPLEXITY API

### Provider Implementation

```python
# apps/ai_gateway/providers/perplexity.py
import httpx
import structlog

from .base import GenerationResult

logger = structlog.get_logger(__name__)

class PerplexityProvider:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.perplexity.ai"
        self.model = "llama-3.1-sonar-large-128k-online"
    
    async def search(
        self,
        query: str,
        *,
        system_prompt: str | None = None,
    ) -> GenerationResult:
        """
        Vyhled√°v√° informace na webu.
        """
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.base_url}/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json",
                },
                json={
                    "model": self.model,
                    "messages": [
                        {
                            "role": "system",
                            "content": system_prompt or "Be precise and concise."
                        },
                        {
                            "role": "user",
                            "content": query
                        }
                    ],
                },
                timeout=60.0,
            )
            response.raise_for_status()
            data = response.json()
        
        return GenerationResult(
            content=data["choices"][0]["message"]["content"],
            input_tokens=data.get("usage", {}).get("prompt_tokens", 0),
            output_tokens=data.get("usage", {}).get("completion_tokens", 0),
            model=self.model,
            provider="perplexity",
            raw_response=data,
        )
    
    async def scrape_company(
        self,
        company_name: str,
        website: str | None = None,
    ) -> dict:
        """
        Scrapuje informace o firmƒõ pro Company DNA.
        """
        query = f"""
        Najdi detailn√≠ informace o firmƒõ "{company_name}":
        1. Obor podnik√°n√≠ a hlavn√≠ produkty/slu≈æby
        2. C√≠lov√° skupina z√°kazn√≠k≈Ø
        3. Hlavn√≠ konkurenti
        4. Tone of voice a styl komunikace
        5. Unik√°tn√≠ prodejn√≠ argumenty (USP)
        6. Historie a zaj√≠mavosti
        
        {"Website: " + website if website else ""}
        
        Odpovƒõz strukturovanƒõ v JSON form√°tu.
        """
        
        result = await self.search(
            query,
            system_prompt="Jsi expert na anal√Ωzu firem. Odpov√≠dej v JSON form√°tu."
        )
        
        # Parse response
        import json
        try:
            return json.loads(result.content)
        except json.JSONDecodeError:
## 4. PERPLEXITY API

### Provider Implementation

```python
# apps/ai_gateway/providers/perplexity.py
import httpx
import structlog

from .base import GenerationResult

logger = structlog.get_logger(__name__)

class PerplexityProvider:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.perplexity.ai"
        self.model = "llama-3.1-sonar-large-128k-online"
    
    async def search(
        self,
        query: str,
        *,
        system_prompt: str | None = None,
    ) -> GenerationResult:
        """
        Vyhled√°v√° informace na webu.
        """
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.base_url}/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json",
                },
                json={
                    "model": self.model,
                    "messages": [
                        {
                            "role": "system",
                            "content": system_prompt or "Be precise and concise."
                        },
                        {
                            "role": "user",
                            "content": query
                        }
                    ],
                },
                timeout=60.0,
            )
            response.raise_for_status()
            data = response.json()
        
        return GenerationResult(
            content=data["choices"][0]["message"]["content"],
            input_tokens=data.get("usage", {}).get("prompt_tokens", 0),
            output_tokens=data.get("usage", {}).get("completion_tokens", 0),
            model=self.model,
            provider="perplexity",
            raw_response=data,
        )
    
    async def scrape_company(
        self,
        company_name: str,
        website: str | None = None,
    ) -> dict:
        """
        Scrapuje informace o firmƒõ pro Company DNA.
        """
        query = f"""
        Najdi detailn√≠ informace o firmƒõ "{company_name}":
        1. Obor podnik√°n√≠ a hlavn√≠ produkty/slu≈æby
        2. C√≠lov√° skupina z√°kazn√≠k≈Ø
        3. Hlavn√≠ konkurenti
        4. Tone of voice a styl komunikace
        5. Unik√°tn√≠ prodejn√≠ argumenty (USP)
        6. Historie a zaj√≠mavosti
        
        {"Website: " + website if website else ""}
        
        Odpovƒõz strukturovanƒõ v JSON form√°tu.
        """
        
        result = await self.search(
            query,
            system_prompt="Jsi expert na anal√Ωzu firem. Odpov√≠dej v JSON form√°tu."
        )
        
        # Parse response
        import json
        try:
            return json.loads(result.content)
        except json.JSONDecodeError:
            return {"raw_info": result.content}
```

**Aktu√°ln√≠ stav implementace:**
- ‚úÖ **PerplexityProvider existuje** - Implementov√°n v `providers/perplexity.py`
- ‚úÖ **API KEY** - `PERPLEXITY_API_KEY` je spr√°vnƒõ nakonfigurov√°n v `.env`
- ‚úÖ **`search()` metoda** - Funguje a pou≈æ√≠v√° se pro web search a research
- ‚úÖ **`scrape_company()` metoda** - **TOTO JE KL√çƒåOV√Å FUNKCE** - pou≈æ√≠v√° se v `scrape_company_dna()` pro z√≠sk√°v√°n√≠ informac√≠ o firm√°ch
- ‚ùå **`structlog`** - Nen√≠ pou≈æit, m√≠sto toho standardn√≠ Python `logging`
- ‚úÖ **HTTP komunikace** - Pou≈æ√≠v√° `httpx.AsyncClient` pro async po≈æadavky
- ‚úÖ **Model**: Pou≈æ√≠v√° `llama-3.1-sonar-large-128k-online` nebo podobn√Ω online model
- ‚úÖ **Timeout handling** - M√° nastaven√Ω 60s timeout
- ‚ö†Ô∏è **Error handling** - Z√°kladn√≠ `raise_for_status()`, mo≈æn√° chyb√≠ retry logika

**Skuteƒçn√© pou≈æit√≠ v aplikaci:**
```python
# Funkce scrape_company_dna() pou≈æ√≠v√° PerplexityProvider:
async def scrape_company_dna(domain: str, organization_id: str):
    provider = get_research_provider()  # Vrac√≠ PerplexityProvider
    
    # Vyhled√° informace o firmƒõ
    query = f"detailn√≠ informace o firmƒõ s dom√©nou {domain}"
    result = await provider.search(query=query)
    
    # Alternativnƒõ m≈Ø≈æe volat p≈ô√≠mo scrape_company():
    # company_info = await provider.scrape_company(
    #     company_name="Firma s.r.o.",
    #     website=domain
    # )
    
    return result.content
```

---

## 5. IMAGE GENERATION (NANOBANA)

### Provider Implementation

```python
# apps/ai_gateway/providers/nanobana.py
import httpx
import structlog

from .base import ImageProviderInterface, ImageResult

logger = structlog.get_logger(__name__)

class NanobanaProvider(ImageProviderInterface):
    """
    Nanobana Pro provider (Imagen 3).
    """
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.nanobana.ai"
    
    async def generate_image(
        self,
        prompt: str,
        *,
        aspect_ratio: str = "1:1",
        style: str | None = None,
        negative_prompt: str | None = None,
    ) -> ImageResult:
        """
        Generuje obr√°zek pomoc√≠ Imagen 3.
        """
        # Build full prompt
        full_prompt = prompt
        if style:
            full_prompt = f"{prompt}, {style} style"
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.base_url}/v1/images/generate",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json",
                },
                json={
                    "prompt": full_prompt,
                    "negative_prompt": negative_prompt or "blurry, low quality, distorted",
                    "aspect_ratio": aspect_ratio,
                    "model": "imagen-3",
                    "output_format": "png",
                },
                timeout=120.0,
            )
            response.raise_for_status()
            data = response.json()
        
## 5. IMAGE GENERATION (NANOBANA)

### Provider Implementation

```python
# apps/ai_gateway/providers/nanobana.py
import httpx
import structlog

from .base import ImageProviderInterface, ImageResult

logger = structlog.get_logger(__name__)

class NanobanaProvider(ImageProviderInterface):
    """
    Nanobana Pro provider (Imagen 3).
    """
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.nanobana.ai"
    
    async def generate_image(
        self,
        prompt: str,
        *,
        aspect_ratio: str = "1:1",
        style: str | None = None,
        negative_prompt: str | None = None,
    ) -> ImageResult:
        """
        Generuje obr√°zek pomoc√≠ Imagen 3.
        """
        # Build full prompt
        full_prompt = prompt
        if style:
            full_prompt = f"{prompt}, {style} style"
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.base_url}/v1/images/generate",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json",
                },
                json={
                    "prompt": full_prompt,
                    "negative_prompt": negative_prompt or "blurry, low quality, distorted",
                    "aspect_ratio": aspect_ratio,
                    "model": "imagen-3",
                    "output_format": "png",
                },
                timeout=120.0,
            )
            response.raise_for_status()
            data = response.json()
        
        return ImageResult(
            url=data["images"][0]["url"],
            prompt_used=full_prompt,
            model="imagen-3",
            provider="nanobana",
        )
```

**Aktu√°ln√≠ stav implementace:**
- ‚ùå **NanobanaProvider NEEXISTUJE** - Nen√≠ implementov√°n, image generation zat√≠m nen√≠ aktivn√≠ feature
- ‚úÖ **API KEY existuje** - `NANOBANA_API_KEY` je v `.env`, ale provider nen√≠ spu≈°tƒõn√Ω
- ‚ùå **`ImageResult` dataclass** - Nen√≠ implementov√°na
- ‚ùå **`ImageProviderInterface`** - Nen√≠ implementov√°na
- ‚ùå **Integrace s Nanobana API** - Nen√≠ implementov√°na
- ‚ö†Ô∏è **Pl√°novan√° feature** - Image generation je na roadmapƒõ pro PRO+ tier

**Status:**
```
üî¥ NEN√ç IMPLEMENTOV√ÅNO
üìã Pl√°nov√°no pro budouc√≠ verzi
üí∞ Souƒç√°st PRO+ subscription tier
```

Image generation je komplexn√≠ feature, kter√° vy≈æaduje:
1. Implementaci NanobanaProvider
2. Image storage (S3/Cloudinary)
3. Feature gating podle subscription tier
4. UI pro image generation
5. Cost tracking pro images

### Visual Prompt Engineering

```python
# apps/ai_gateway/visual_prompt.py

class VisualPromptEngineer:
    """
    Generuje optimalizovan√© prompty pro image generation.
    Implementuje "Authenticity Trend 2026" logiku.
    """
    
    # Industry -> Authenticity fit mapping
    HIGH_AUTHENTICITY_INDUSTRIES = [
        'personal_brand', 'small_business', 'local', 'nonprofit',
        'fitness', 'creative', 'eco', 'startup', 'community'
    ]
    
    LOW_AUTHENTICITY_INDUSTRIES = [
        'luxury', 'finance', 'legal', 'healthcare', 'corporate',
        'real_estate', 'enterprise'
    ]
    
    PLATFORM_ASPECTS = {
        'instagram_feed': '1:1',
        'instagram_story': '9:16',
        'facebook_feed': '16:9',
        'linkedin': '16:9',
        'tiktok': '9:16',
        'twitter': '16:9',
        'pinterest': '2:3',
    }
    
    def generate_prompt(
        self,
        message: str,
        persona,
        platform: str,
        industry: str | None = None,
    ) -> dict:
        """
        Generuje image prompt na z√°kladƒõ kontextu.
        """
        aspect_ratio = self.PLATFORM_ASPECTS.get(platform, '1:1')
        authenticity = self._determine_authenticity(industry or '')
        
        # Build base prompt
        prompt_parts = [
            f"[{aspect_ratio} aspect ratio]",
        ]
        
        # Add visual style from persona
        if persona.art_style_name:
            prompt_parts.append(f"[{persona.art_style_name} style]")
        
        if persona.color_palette:
            prompt_parts.append(f"[{persona.color_palette} color palette]")
        
        if persona.visual_atmosphere:
            prompt_parts.append(f"[{persona.visual_atmosphere} mood]")
        
        # Add authenticity modifiers
        if authenticity == 'high':
            prompt_parts.extend([
                "natural lighting",
                "authentic moment",
                "candid feel",
                "real environment",
            ])
        else:
            prompt_parts.extend([
                "professional photography",
                "studio quality",
                "polished composition",
                "editorial style",
            ])
        
        # Add content
        prompt_parts.append(message)
        
        # Add quality
        prompt_parts.append("high-quality, professional")
        
        full_prompt = ", ".join(prompt_parts)
        
        return {
            "prompt": full_prompt,
            "negative_prompt": "blurry, low quality, distorted, ugly, watermark, text, logo",
            "aspect_ratio": aspect_ratio,
            "authenticity_level": authenticity,
        }
    
    def _determine_authenticity(self, industry: str) -> str:
        """Urƒç√≠ √∫rove≈à authenticity podle industry."""
        industry_lower = industry.lower()
        
        for ind in self.HIGH_AUTHENTICITY_INDUSTRIES:
            if ind in industry_lower:
                return 'high'
        
        for ind in self.LOW_AUTHENTICITY_INDUSTRIES:
            if ind in industry_lower:
                return 'low'
        
        return 'medium'
```

---

## 6. VIDEO GENERATION (VEO 3)

### Provider Implementation

```python
# apps/ai_gateway/providers/veo.py
import httpx
import asyncio
import structlog

logger = structlog.get_logger(__name__)

class VeoProvider:
    """
    Veo 3 video generation provider.
    ULTIMATE tier only.
    """
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.veo.google"
    
    async def generate_video(
        self,
        prompt: str,
        *,
        duration: int = 6,  # 6-10 seconds
        aspect_ratio: str = "16:9",
        style: str | None = None,
    ) -> dict:
        """
        Generuje kr√°tk√© video.
        """
        full_prompt = prompt
        if style:
            full_prompt = f"{prompt}, {style} style"
        
        async with httpx.AsyncClient() as client:
            # Start generation
            response = await client.post(
                f"{self.base_url}/v1/videos/generate",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                },
                json={
                    "prompt": full_prompt,
                    "duration_seconds": duration,
                    "aspect_ratio": aspect_ratio,
                    "model": "veo-3",
                },
                timeout=30.0,
            )
            response.raise_for_status()
            job = response.json()
            
            # Poll for completion
            job_id = job["id"]
            max_attempts = 60  # 5 minutes max
            
            for _ in range(max_attempts):
                status_response = await client.get(
                    f"{self.base_url}/v1/videos/{job_id}",
                    headers={"Authorization": f"Bearer {self.api_key}"},
                )
                status_response.raise_for_status()
                status = status_response.json()
                
                if status["status"] == "completed":
                    return {
                        "url": status["video_url"],
                        "thumbnail_url": status.get("thumbnail_url"),
                        "duration": status["duration"],
                        "prompt_used": full_prompt,
                    }
                elif status["status"] == "failed":
                    raise Exception(f"Video generation failed: {status.get('error')}")
                
                await asyncio.sleep(5)  # Poll every 5 seconds
            
## 6. VIDEO GENERATION (VEO 3)

### Provider Implementation

```python
# apps/ai_gateway/providers/veo.py
import httpx
import asyncio
import structlog

logger = structlog.get_logger(__name__)

class VeoProvider:
    """
    Veo 3 video generation provider.
    ULTIMATE tier only.
    """
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.veo.google"
    
    async def generate_video(
        self,
        prompt: str,
        *,
        duration: int = 6,  # 6-10 seconds
        aspect_ratio: str = "16:9",
        style: str | None = None,
    ) -> dict:
        """
        Generuje kr√°tk√© video.
        """
        full_prompt = prompt
        if style:
            full_prompt = f"{prompt}, {style} style"
        
        async with httpx.AsyncClient() as client:
            # Start generation
            response = await client.post(
                f"{self.base_url}/v1/videos/generate",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                },
                json={
                    "prompt": full_prompt,
                    "duration_seconds": duration,
                    "aspect_ratio": aspect_ratio,
                    "model": "veo-3",
                },
                timeout=30.0,
            )
            response.raise_for_status()
            job = response.json()
            
            # Poll for completion
            job_id = job["id"]
            max_attempts = 60  # 5 minutes max
            
            for _ in range(max_attempts):
                status_response = await client.get(
                    f"{self.base_url}/v1/videos/{job_id}",
                    headers={"Authorization": f"Bearer {self.api_key}"},
                )
                status_response.raise_for_status()
                status = status_response.json()
                
                if status["status"] == "completed":
                    return {
                        "url": status["video_url"],
                        "thumbnail_url": status.get("thumbnail_url"),
                        "duration": status["duration"],
                        "prompt_used": full_prompt,
                    }
                elif status["status"] == "failed":
                    raise Exception(f"Video generation failed: {status.get('error')}")
                
                await asyncio.sleep(5)  # Poll every 5 seconds
            
            raise TimeoutError("Video generation timed out")
```

**Aktu√°ln√≠ stav implementace:**
- ‚ùå **VeoProvider NEEXISTUJE** - Nen√≠ implementov√°n, video generation nen√≠ aktivn√≠
- ‚úÖ **API KEY existuje** - `VEO_API_KEY` je v `.env`, ale provider nen√≠ spu≈°tƒõn√Ω
- ‚ùå **Video generation** - Nen√≠ implementov√°na ≈æ√°dn√° ƒç√°st video generov√°n√≠
- ‚ùå **Job polling system** - Nen√≠ implementov√°n asynchronn√≠ polling system
- ‚ùå **Video storage** - Nen√≠ implementov√°no storage pro vygenerovan√° videa
- ‚ö†Ô∏è **Pl√°novan√° feature** - Video generation je na roadmapƒõ pro ULTIMATE tier

**Status:**
```
üî¥ NEN√ç IMPLEMENTOV√ÅNO
üìã Pl√°nov√°no pro budouc√≠ verzi
üí∞ Souƒç√°st ULTIMATE subscription tier (nejvy≈°≈°√≠ tier)
‚è±Ô∏è Vy≈æaduje komplexn√≠ polling system a video storage
```

Video generation je nejslo≈æitƒõj≈°√≠ a nejdra≈æ≈°√≠ feature, kter√° vy≈æaduje:
1. Implementaci VeoProvider s async polling
2. Video storage (S3/specialized video CDN)
3. Feature gating - pouze ULTIMATE tier
4. UI pro video generation a preview
5. Cost tracking (velmi drah√© - $0.05/sekunda)
6. Queue system pro dlouh√© video jobs

---

## 7. PROMPT ENGINEERING

### Prompt Templates

```python
# Ulo≈æeno v datab√°zi jako PromptTemplate

**Aktu√°ln√≠ stav implementace:**
- ‚ùå **`PromptTemplate` DB model NEEXISTUJE** - Tento model nen√≠ implementov√°n
- ‚úÖ **`AIJob` model EXISTUJE** - M√≠sto PromptTemplate existuje model pro tracking AI job≈Ø
- ‚ùå **Template management** - Nen√≠ syst√©m pro spr√°vu a verzov√°n√≠ prompt templates
- ‚ö†Ô∏è **Prompty jsou HARDCODED** - V≈°echny prompty jsou p≈ô√≠mo v service funkc√≠ch, ne v DB
- ‚ùå **Jinja2 templating** - Nen√≠ pou≈æ√≠v√°n pro dynamic prompt rendering
- ‚ùå **Template versioning** - Nen√≠ syst√©m verzov√°n√≠ (V1, V2, V3...)
- ‚ùå **Template types** - Nen√≠ kategorizace podle typu (persona, topic, blogpost, social_post)

**Co SKUTEƒåNƒö existuje - `AIJob` model:**

M√≠sto `PromptTemplate` modelu pro ≈°ablony, aplikace m√° `AIJob` model pro tracking AI operac√≠:

```python
# apps/ai_gateway/models.py (skuteƒçn√Ω k√≥d)
from django.db import models
from apps.core.models import BaseModel

class JobStatus(models.TextChoices):
    """AI job status choices."""
    PENDING = 'pending', 'Pending'
    PROCESSING = 'processing', 'Processing'
    COMPLETED = 'completed', 'Completed'
    FAILED = 'failed', 'Failed'
    CANCELLED = 'cancelled', 'Cancelled'

class JobType(models.TextChoices):
    """AI job type choices."""
    SCRAPE_DNA = 'scrape_dna', 'Scrape Company DNA'
    GENERATE_PERSONAS = 'generate_personas', 'Generate Personas'
    GENERATE_TOPICS = 'generate_topics', 'Generate Topics'
    GENERATE_BLOGPOST = 'generate_blogpost', 'Generate Blog Post'
    GENERATE_SOCIAL = 'generate_social', 'Generate Social Posts'
    GENERATE_IMAGE = 'generate_image', 'Generate Image'
    GENERATE_VIDEO = 'generate_video', 'Generate Video'

class AIJob(BaseModel):
    """
    Tracks AI generation jobs.
    
    CRITICAL: AIJob belongs to COMPANY (content tenant), not Organization!
    """
    company = models.ForeignKey('companies.Company', on_delete=models.CASCADE)
    created_by = models.ForeignKey('users.User', on_delete=models.SET_NULL, null=True)
    
    # Job identification
    job_type = models.CharField(max_length=30, choices=JobType.choices)
    status = models.CharField(max_length=20, choices=JobStatus.choices, default=JobStatus.PENDING)
    
    # Data
    input_data = models.JSONField(default=dict)
    output_data = models.JSONField(default=dict, blank=True)
    
    # Error tracking
    error_message = models.TextField(blank=True)
    error_details = models.JSONField(default=dict, blank=True)
    
    # Timing
    started_at = models.DateTimeField(null=True, blank=True)
    completed_at = models.DateTimeField(null=True, blank=True)
    
    # Retry logic
    retry_count = models.IntegerField(default=0)
    max_retries = models.IntegerField(default=3)
    
    # Celery integration
    celery_task_id = models.CharField(max_length=255, blank=True)
    priority = models.IntegerField(default=5)
    
    # Usage tracking
    tokens_used = models.IntegerField(default=0)
    generation_time_seconds = models.FloatField(null=True, blank=True)
    
    def mark_processing(self):
        """Mark job as processing."""
        self.status = JobStatus.PROCESSING
        self.started_at = timezone.now()
        self.save()
    
    def mark_completed(self, output_data: dict, tokens_used: int = 0):
        """Mark job as completed."""
        self.status = JobStatus.COMPLETED
        self.output_data = output_data
        self.completed_at = timezone.now()
        self.tokens_used = tokens_used
        self.save()
    
    def mark_failed(self, error_message: str, error_details: dict = None):
        """Mark job as failed."""
        self.status = JobStatus.FAILED
        self.error_message = error_message
        self.error_details = error_details or {}
        self.completed_at = timezone.now()
        self.save()
```

**Kl√≠ƒçov√© vlastnosti `AIJob` modelu:**
- ‚úÖ **Job tracking** - Sleduje v≈°echny AI operace (scraping, generation)
- ‚úÖ **Status management** - PENDING ‚Üí PROCESSING ‚Üí COMPLETED/FAILED
- ‚úÖ **Celery integration** - Ukl√°d√° `celery_task_id` pro async tracking
- ‚úÖ **Retry logic** - Automatick√© retry s max 3 pokusy
- ‚úÖ **Usage tracking** - Sleduje `tokens_used` a `generation_time_seconds`
- ‚úÖ **Error handling** - Ukl√°d√° error messages a details
- ‚úÖ **Company-scoped** - Pat≈ô√≠ k Company, ne Organization (multi-tenancy)

**Skuteƒçn√© pou≈æit√≠ v aplikaci:**
```python
# Services pou≈æ√≠vaj√≠ hardcoded prompty, ne DB templates:

def scrape_company_dna(*, website: str, company_name: str) -> dict:
    """Scrape company DNA using Perplexity."""
    provider = get_research_provider()
    
    # ‚ùå Prompt je HARDCODED, ne z DB
    prompt = f'''Research the company "{company_name}" with website {website}.

Find and return comprehensive information about:

1. **Mission & Vision**
   - Company mission statement
   - Company vision
   
2. **Values & Culture**
   - Core company values
   
3. **Target Audience**
   - Primary customer segments
   
... (full prompt hardcoded here)
'''
    
    schema = {
        'mission': 'string - Company mission',
        'vision': 'string - Company vision',
        'values': ['string - Core value'],
        # ... schema je taky hardcoded
    }
    
    result = provider.generate_json(prompt, schema)
    return result


def generate_personas(*, company_dna: dict, count: int = 6) -> list[dict]:
    """Generate personas based on company DNA."""
    provider = get_text_provider()
    
    # ‚ùå Prompt je opƒõt HARDCODED
    prompt = f'''Create {count} unique fictional author personas.

Company Information:
- Name: {company_dna.get('name')}
- Industry: {company_dna.get('industry')}
- Mission: {company_dna.get('mission')}

Requirements for each persona:
1. Unique Identity
2. Psychology: Jung archetype and MBTI
3. Personal Values: 3-5 values
... (full prompt hardcoded)
'''
    
    schema = {
        'personas': [
            {
                'name': 'string - Full name',
                'bio': 'string - Biography',
                'archetype': 'string - Jung archetype',
                'mbti': 'string - MBTI type',
                # ... schema hardcoded
            }
        ]
    }
    
    result = provider.generate_json(prompt, schema)
    return result['personas']
```

**Proƒç je to probl√©m:**
- üîÑ **Tƒõ≈æk√° √∫dr≈æba** - Zmƒõna promptu vy≈æaduje code deploy, ne DB update
- üìù **≈Ω√°dn√© verzov√°n√≠** - Nelze A/B testovat r≈Øzn√© verze prompt≈Ø
- üîç **≈Ω√°dn√Ω audit trail** - Nen√≠ historie zmƒõn prompt≈Ø
- üë• **Vy≈æaduje program√°tora** - Content mana≈æer nem≈Ø≈æe upravit prompty bez code zmƒõny
- üéØ **≈Ω√°dn√° optimalizace** - Nelze trackovat kter√© prompt verze funguj√≠ nejl√©pe

**Co je pot≈ôeba implementovat:**
1. ‚úÖ Vytvo≈ôit `PromptTemplate` model v Django
2. ‚úÖ P≈ôidat fields: `code`, `name`, `template_type`, `system_prompt`, `user_prompt_template`, `temperature`, `max_tokens`, `version`
3. ‚úÖ Migrovat v≈°echny hardcoded prompty do datab√°ze
4. ‚úÖ Implementovat Jinja2 rendering pro variables (`{{ company.name }}`, `{% for persona in personas %}`)
5. ‚úÖ Vytvo≈ôit management commands pro import/export templates
6. ‚úÖ P≈ôidat versioning system (V1, V2, V3...) s mo≈ænost√≠ A/B testingu
7. ‚úÖ UI pro editaci templates v admin rozhran√≠ nebo custom UI
8. ‚úÖ Integrovat do services - m√≠sto hardcoded prompt≈Ø naƒç√≠tat z DB

# =============================================================================
# PERSONA GENERATION
# =============================================================================
PERSONA_GEN_V1 = {
    "code": "PERSONA_GEN_V1",
    "name": "Persona Generation v1",
    "template_type": "persona",
    "system_prompt": """Jsi expert na tvorbu brand person a obsahovou strategii pro ƒçesk√© firmy. 
Tv√Ωm √∫kolem je vytvo≈ôit 6 unik√°tn√≠ch, realistick√Ωch a diverzifikovan√Ωch person.

Ka≈æd√° persona mus√≠ b√Ωt:
1. Unik√°tn√≠ v kombinaci archetypu, MBTI a perspektivy
2. Relevantn√≠ pro dan√Ω obor podnik√°n√≠
3. Schopn√° komunikovat s c√≠lovou skupinou firmy

D≈ÆLE≈ΩIT√â: Nikdy neopakuj stejnou kombinaci Jungova archetypu nebo MBTI typu!""",
    
    "user_prompt_template": """Vytvo≈ô 6 unik√°tn√≠ch person pro firmu:

=== INFORMACE O FIRMƒö ===
N√°zev: {{ company.name }}
Obor: {{ company.business_field }}
Produkt/slu≈æba: {{ company.product_type }}

=== C√çLOV√Å SKUPINA ===
{{ company.company_dna.target_audience | default('Nespecifikov√°no') }}

=== PO≈ΩADAVKY ===
- 6 R≈ÆZN√ùCH Jungov√Ωch archetyp≈Ø
- 6 R≈ÆZN√ùCH MBTI typ≈Ø
- R≈Øzn√© √∫rovnƒõ hierarchie

Vra≈• JSON s polem "personas" obsahuj√≠c√≠m 6 person.""",
    
    "temperature": 0.8,
    "max_tokens": 8192,
}

# =============================================================================
# TOPIC GENERATION
# =============================================================================
TOPIC_GEN_V1 = {
    "code": "TOPIC_GEN_V1",
    "name": "Topic Generation v1",
    "template_type": "topic",
    "system_prompt": """Jsi expert na obsahovou strategii a SEO pro ƒçesk√© firmy.
Vytv√°≈ô√≠≈° promy≈°len√© obsahov√© pl√°ny t√©mat pro blogov√© p≈ô√≠spƒõvky.

Ka≈æd√© t√©ma mus√≠:
1. B√Ωt relevantn√≠ pro obor firmy
2. M√≠t jasn√Ω SEO potenci√°l
3. B√Ωt p≈ôi≈ôazeno konkr√©tn√≠ personƒõ""",
    
    "user_prompt_template": """Vytvo≈ô {{ posts_count }} t√©mat pro mƒõs√≠c {{ month }}/{{ year }}:

=== FIRMA ===
N√°zev: {{ company.name }}
Obor: {{ company.business_field }}

=== PERSONY ===
{% for persona in personas %}
- {{ persona.character_name }} ({{ persona.jung_archetype }})
{% endfor %}

=== PRAVIDLA ===
- Rozdƒõl t√©mata rovnomƒõrnƒõ mezi persony
- Napl√°nuj t√©mata p≈ôes cel√Ω mƒõs√≠c

Vra≈• JSON s polem "topics".""",
    
    "temperature": 0.7,
    "max_tokens": 4096,
}

# =============================================================================
# BLOGPOST GENERATION
# =============================================================================
BLOGPOST_GEN_V1 = {
    "code": "BLOGPOST_GEN_V1",
    "name": "Blogpost Generation v1",
    "template_type": "blogpost",
    "system_prompt": """Jsi zku≈°en√Ω copywriter. P√≠≈°e≈° jako konkr√©tn√≠ persona - s jej√≠m hlasem, slovn√≠kem a zp≈Øsobem argumentace.

Blogpost mus√≠ obsahovat:
1. Magnetick√Ω titulek s focus keyword
2. Strukturovan√© sekce (intro, body, conclusion)
3. FAQ sekci
4. Key takeaways
5. 1500-2500 slov""",
    
    "user_prompt_template": """Napi≈° blogpost na t√©ma:

=== T√âMA ===
Titulek: {{ topic.title }}
Popis: {{ topic.description }}
Focus keyword: {{ topic.focus_keyword }}

=== PERSONA ===
Jm√©no: {{ persona.character_name }}
Archetyp: {{ persona.jung_archetype }}
MBTI: {{ persona.mbti_type }}
Slovn√≠ z√°soba: {{ persona.vocabulary_level }}
Obl√≠ben√© fr√°ze: {{ persona.favorite_phrases }}
Typick√Ω z√°vƒõr: {{ persona.unique_signature_ending }}

=== FIRMA ===
{{ company.name }} - {{ company.business_field }}

Vra≈• strukturovan√Ω JSON.""",
    
    "temperature": 0.7,
    "max_tokens": 12000,
}

# =============================================================================
# SOCIAL POST GENERATION
# =============================================================================
SOCIAL_POST_GEN_V1 = {
    "code": "SOCIAL_POST_GEN_V1",
    "name": "Social Post Generation v1",
    "template_type": "social_post",
    "system_prompt": """Jsi expert na soci√°ln√≠ s√≠tƒõ a vir√°ln√≠ obsah.
Transformuje≈° blogposty do p≈ô√≠spƒõvk≈Ø pro konkr√©tn√≠ platformy.""",
    
    "user_prompt_template": """Vytvo≈ô p≈ô√≠spƒõvek pro {{ platform }}:

=== BLOGPOST ===
Titulek: {{ blogpost.title }}
Key takeaways:
{% for takeaway in blogpost.key_takeaways %}
- {{ takeaway }}
{% endfor %}

=== PERSONA ===
{{ persona.character_name }} - {{ persona.jung_archetype }}
Obl√≠ben√© fr√°ze: {{ persona.favorite_phrases }}

=== PLATFORMA: {{ platform | upper }} ===
{% if platform == 'instagram' %}
Max d√©lka: 2200 znak≈Ø
5-15 hashtag≈Ø
Hook v prvn√≠ vƒõtƒõ
{% elif platform == 'linkedin' %}
Profesion√°ln√≠ t√≥n
3-5 hashtag≈Ø
Hook v prvn√≠ch 2 ≈ô√°dc√≠ch
{% elif platform == 'twitter' %}
Max 280 znak≈Ø
1-2 hashtagy
{% endif %}

Vra≈• JSON s textContent, hashtags, ctaText.""",
    
    "temperature": 0.75,
    "max_tokens": 2048,
}
```

---

## 8. COST TRACKING

### Cost Tracker

```python
# apps/ai_gateway/cost_tracker.py
from decimal import Decimal
from django.core.cache import cache
from django.utils import timezone

# Ceny za 1000 token≈Ø (USD)
COST_PER_1K_TOKENS = {
    'gemini': {
        'input': Decimal('0.00025'),
        'output': Decimal('0.0005'),
    },
    'perplexity': {
        'input': Decimal('0.001'),
        'output': Decimal('0.001'),
    },
}

# Ceny za obr√°zek/video
COST_PER_IMAGE = {
    'nanobana': Decimal('0.02'),
}

COST_PER_VIDEO_SECOND = {
    'veo': Decimal('0.05'),
}

class CostTracker:
    def __init__(self):
        self.cache_prefix = "ai_cost"
    
    async def track(
        self,
        organization,
        provider: str,
        input_tokens: int,
        output_tokens: int,
    ) -> Decimal:
        """Sleduje cost za text generov√°n√≠."""
        costs = COST_PER_1K_TOKENS.get(provider, {})
        
        input_cost = (Decimal(input_tokens) / 1000) * costs.get('input', Decimal('0'))
        output_cost = (Decimal(output_tokens) / 1000) * costs.get('output', Decimal('0'))
        total_cost = input_cost + output_cost
        
        # Update cache counter
        cache_key = f"{self.cache_prefix}:{organization.id}:{timezone.now().strftime('%Y-%m')}"
        current = cache.get(cache_key, Decimal('0'))
        cache.set(cache_key, current + total_cost, timeout=60*60*24*31)  # 31 days
        
        # Update usage record in DB (async)
        from apps.billing.tasks import update_usage_record
        update_usage_record.delay(
            str(organization.id),
            tokens=input_tokens + output_tokens,
            cost=float(total_cost),
        )
        
        return total_cost
    
    async def track_image(
        self,
        organization,
        provider: str,
    ) -> Decimal:
        """Sleduje cost za image generov√°n√≠."""
        cost = COST_PER_IMAGE.get(provider, Decimal('0'))
        
        cache_key = f"{self.cache_prefix}:{organization.id}:{timezone.now().strftime('%Y-%m')}"
        current = cache.get(cache_key, Decimal('0'))
        cache.set(cache_key, current + cost, timeout=60*60*24*31)
        
        from apps.billing.tasks import update_usage_record
        update_usage_record.delay(
            str(organization.id),
            images=1,
            cost=float(cost),
        )
        
        return cost
    
    def get_monthly_cost(self, organization) -> Decimal:
        """Z√≠sk√° aktu√°ln√≠ mƒõs√≠ƒçn√≠ cost."""
## 8. COST TRACKING

### Cost Tracker

```python
# apps/ai_gateway/cost_tracker.py
from decimal import Decimal
from django.core.cache import cache
from django.utils import timezone

# Ceny za 1000 token≈Ø (USD)
COST_PER_1K_TOKENS = {
    'gemini': {
        'input': Decimal('0.00025'),
        'output': Decimal('0.0005'),
    },
    'perplexity': {
        'input': Decimal('0.001'),
        'output': Decimal('0.001'),
    },
}

# Ceny za obr√°zek/video
COST_PER_IMAGE = {
    'nanobana': Decimal('0.02'),
}

COST_PER_VIDEO_SECOND = {
    'veo': Decimal('0.05'),
}

class CostTracker:
    def __init__(self):
        self.cache_prefix = "ai_cost"
    
    async def track(
        self,
        organization,
        provider: str,
        input_tokens: int,
        output_tokens: int,
    ) -> Decimal:
        """Sleduje cost za text generov√°n√≠."""
        costs = COST_PER_1K_TOKENS.get(provider, {})
        
        input_cost = (Decimal(input_tokens) / 1000) * costs.get('input', Decimal('0'))
        output_cost = (Decimal(output_tokens) / 1000) * costs.get('output', Decimal('0'))
        total_cost = input_cost + output_cost
        
        # Update cache counter
        cache_key = f"{self.cache_prefix}:{organization.id}:{timezone.now().strftime('%Y-%m')}"
        current = cache.get(cache_key, Decimal('0'))
        cache.set(cache_key, current + total_cost, timeout=60*60*24*31)  # 31 days
        
        # Update usage record in DB (async)
        from apps.billing.tasks import update_usage_record
        update_usage_record.delay(
            str(organization.id),
            tokens=input_tokens + output_tokens,
            cost=float(total_cost),
        )
        
        return total_cost
    
    async def track_image(
        self,
        organization,
        provider: str,
    ) -> Decimal:
        """Sleduje cost za image generov√°n√≠."""
        cost = COST_PER_IMAGE.get(provider, Decimal('0'))
        
        cache_key = f"{self.cache_prefix}:{organization.id}:{timezone.now().strftime('%Y-%m')}"
        current = cache.get(cache_key, Decimal('0'))
        cache.set(cache_key, current + cost, timeout=60*60*24*31)
        
        from apps.billing.tasks import update_usage_record
        update_usage_record.delay(
            str(organization.id),
            images=1,
            cost=float(cost),
        )
        
        return cost
    
    def get_monthly_cost(self, organization) -> Decimal:
        """Z√≠sk√° aktu√°ln√≠ mƒõs√≠ƒçn√≠ cost."""
        cache_key = f"{self.cache_prefix}:{organization.id}:{timezone.now().strftime('%Y-%m')}"
        return cache.get(cache_key, Decimal('0'))
```

**Aktu√°ln√≠ stav implementace:**
- ‚ùå **`CostTracker` t≈ô√≠da NEEXISTUJE** - Nen√≠ implementov√°na ≈æ√°dn√° centr√°ln√≠ cost tracking t≈ô√≠da
- ‚ùå **Cost tracking per provider** - Nen√≠ sledov√°n√≠ n√°klad≈Ø podle providera (gemini, perplexity)
- ‚ùå **Cache-based counters** - Nen√≠ implementov√°no ukl√°d√°n√≠ mƒõs√≠ƒçn√≠ch n√°klad≈Ø do cache
- ‚ùå **Integration s billing** - Nen√≠ propojen√≠ s `apps.billing.tasks.update_usage_record`
- ‚ùå **Cost constants** - Konstanty `COST_PER_1K_TOKENS`, `COST_PER_IMAGE`, `COST_PER_VIDEO_SECOND` nejsou definov√°ny
- ‚ùå **Monthly aggregation** - Nen√≠ funkce `get_monthly_cost()`
- ‚ö†Ô∏è **Token counts jsou k dispozici** - Gemini a Perplexity vracej√≠ `input_tokens` a `output_tokens` v response, ale nejsou sledov√°ny

**Skuteƒçn√Ω stav:**
```python
# Realita: ≈Ω√°dn√Ω cost tracking
# Token counts jsou dostupn√© v GenerationResult, ale nejsou sledov√°ny:

@dataclass
class GenerationResult:
    content: str
    input_tokens: int      # ‚úÖ K dispozici z API
    output_tokens: int     # ‚úÖ K dispozici z API
    model: str
    provider: str

# Ale nejsou nikam persistov√°ny ani agregov√°ny! ‚ùå
```

**Co je pot≈ôeba implementovat:**
1. ‚úÖ Vytvo≈ôit `CostTracker` t≈ô√≠du v `apps/ai_gateway/cost_tracker.py`
2. ‚úÖ Definovat cost constants pro v≈°echny providery
3. ‚úÖ Implementovat `track()` metodu pro text generation tracking
4. ‚úÖ Implementovat `track_image()` a `track_video()` metody
5. ‚úÖ Vytvo≈ôit `update_usage_record` Celery task v `apps.billing.tasks`
6. ‚úÖ Integrovat do v≈°ech provider vol√°n√≠ (GeminiProvider, PerplexityProvider)
7. ‚úÖ Vytvo≈ôit billing reports pro organizace
8. ‚úÖ P≈ôidat cost monitoring dashboard

---

## 9. CACHING & OPTIMIZATION

### Semantic Cache

```python
# apps/ai_gateway/cache.py
from django.core.cache import cache
import hashlib

class AICache:
    """Cache pro AI responses."""
    
    PREFIX = "ai_response"
    DEFAULT_TTL = 3600  # 1 hour
    
    @classmethod
    def get_key(cls, prompt: str, model: str) -> str:
        """Generuje cache key z promptu."""
        content = f"{model}:{prompt}"
        return f"{cls.PREFIX}:{hashlib.sha256(content.encode()).hexdigest()}"
    
    @classmethod
    def get(cls, prompt: str, model: str) -> str | None:
        """Z√≠sk√° cached response."""
        key = cls.get_key(prompt, model)
        return cache.get(key)
    
    @classmethod
    def set(cls, prompt: str, model: str, response: str, ttl: int = None):
        """Ulo≈æ√≠ response do cache."""
        key = cls.get_key(prompt, model)
        cache.set(key, response, ttl or cls.DEFAULT_TTL)
    
### Rate Limiting

```python
# apps/ai_gateway/rate_limiter.py
from django.core.cache import cache
import time

class AIRateLimiter:
    """Rate limiter pro AI API vol√°n√≠."""
    
    # Limity per provider per minute
    LIMITS = {
        'gemini': 60,
        'perplexity': 50,
        'nanobana': 10,
        'veo': 5,
    }
    
    @classmethod
    def check(cls, provider: str, organization_id: str) -> bool:
        """Kontroluje zda lze prov√©st vol√°n√≠."""
        key = f"rate_limit:{provider}:{organization_id}"
        current = cache.get(key, 0)
        limit = cls.LIMITS.get(provider, 60)
        return current < limit
    
    @classmethod
    def increment(cls, provider: str, organization_id: str):
        """Inkrementuje counter."""
        key = f"rate_limit:{provider}:{organization_id}"
        current = cache.get(key, 0)
        cache.set(key, current + 1, timeout=60)  # Reset every minute
    
---

## üìå QUICK REFERENCE

### Environment Variables

```bash
GEMINI_API_KEY=your-gemini-api-key
PERPLEXITY_API_KEY=your-perplexity-api-key
NANOBANA_API_KEY=your-nanobana-api-key
VEO_API_KEY=your-veo-api-key
```

### Usage Example

```python
from apps.ai_gateway.services import AIGateway
from apps.ai_gateway.models import PromptTemplate

gateway = AIGateway()

# Text generation
template = PromptTemplate.objects.get(code='BLOGPOST_GEN_V1')
result = await gateway.generate(
    prompt_template=template,
    variables={'topic': topic, 'persona': persona, 'company': company},
    organization=organization,
)

# Image generation
image = await gateway.generate_image(
    prompt="Professional business meeting in modern office",
    organization=organization,
    aspect_ratio="16:9",
)
```

**Aktu√°ln√≠ stav implementace pro QUICK REFERENCE:**
- ‚úÖ **Environment Variables** - V≈°echny 4 API keys jsou spr√°vnƒõ nakonfigurov√°ny v `.env`
- ‚ùå **AIGateway t≈ô√≠da** - NEEXISTUJE, m√≠sto toho se pou≈æ√≠vaj√≠ factory funkce
- ‚ùå **PromptTemplate model** - NEEXISTUJE, prompty jsou hardcoded
- ‚ùå **Usage example** - K√≥d v p≈ô√≠kladu NEFUNGUJE, proto≈æe `AIGateway()` t≈ô√≠da neexistuje

**Skuteƒçn√© pou≈æit√≠:**
```python
# Realita - funkcion√°ln√≠ factory pattern:
from apps.ai_gateway.providers import get_text_provider, get_research_provider

# Text generation (Gemini)
text_provider = get_text_provider()
result = await text_provider.generate_text(
    system_prompt="Jsi expert na...",
    user_prompt="Vytvo≈ô blogpost o...",
    temperature=0.7,
    max_tokens=4096,
)

# Research (Perplexity)
research_provider = get_research_provider()
company_info = await research_provider.search(
    query=f"informace o firmƒõ {domain}"
)
```

---

## üìä IMPLEMENTATION STATUS SUMMARY

### ‚úÖ CO JE IMPLEMENTOV√ÅNO (Funguje v produkci)

| Komponenta | Status | Detail |
|------------|--------|--------|
| **GeminiProvider** | ‚úÖ Funguje | Text generation pomoc√≠ Gemini 1.5 Pro |
| **PerplexityProvider** | ‚úÖ Funguje | Web search a company scraping |
| **API Keys** | ‚úÖ Nakonfigurov√°ny | V≈°echny 4 keys v `.env` |
| **GenerationResult dataclass** | ‚úÖ Existuje | Pro n√°vratov√© hodnoty |
| **Factory functions** | ‚úÖ Funguj√≠ | `get_text_provider()`, `get_research_provider()` |
| **`scrape_company_dna()`** | ‚úÖ Funguje | Kl√≠ƒçov√° funkce pro onboarding |
| **Async support** | ‚úÖ Funguje | V≈°echny providery jsou async |
| **Token counts** | ‚úÖ K dispozici | V response metadata |

### ‚ùå CO NEN√ç IMPLEMENTOV√ÅNO (Pouze pl√°n)

| Komponenta | D≈Øvod absence | Priorita |
|------------|---------------|----------|
| **AIGateway t≈ô√≠da** | Pou≈æ√≠v√° se funkcion√°ln√≠ p≈ô√≠stup m√≠sto OOP | üü° Medium |
| **CostTracker** | Nen√≠ sledov√°n√≠ n√°klad≈Ø | üî¥ High |
| **PromptTemplate model** | Prompty jsou hardcoded | üü° Medium |
| **AICache** | Nen√≠ caching AI responses | üî¥ High |
| **AIRateLimiter** | Nen√≠ rate limiting | üü° Medium |
| **NanobanaProvider** | Image generation nen√≠ aktivn√≠ | üü¢ Low |
| **VeoProvider** | Video generation nen√≠ aktivn√≠ | üü¢ Low |
| **ImageResult dataclass** | Nen√≠ pot≈ôeba bez image gen | üü¢ Low |
| **structlog** | Pou≈æ√≠v√° se standardn√≠ `logging` | üü¢ Low |
| **litellm** | Je v requirements, ale je zakomentovan√Ω | üü¢ Low |
| **tiktoken** | Nen√≠ pro p≈ôesn√© poƒç√≠t√°n√≠ token≈Ø | üü¢ Low |

### üéØ PRIORITY IMPLEMENTACE (Co implementovat jako prvn√≠)

**üî¥ HIGH PRIORITY** (Kritick√© pro produkci):
1. **CostTracker** - Sledov√°n√≠ n√°klad≈Ø per organizace, kritick√© pro billing
2. **AICache** - Sn√≠≈æen√≠ n√°klad≈Ø a latence, snadn√° win
3. **Error handling & retries** - Robustn√≠ handling API selh√°n√≠

**üü° MEDIUM PRIORITY** (Zlep≈°en√≠ architektury):
4. **PromptTemplate model** - Lep≈°√≠ spr√°va prompt≈Ø, verzov√°n√≠
5. **AIRateLimiter** - Ochrana p≈ôed p≈ôekroƒçen√≠m limit≈Ø
6. **AIGateway t≈ô√≠da** - Centralizace logiky (nebo ponechat factory pattern)
7. **Monitoring & metrics** - Sledov√°n√≠ vyu≈æit√≠ API

**üü¢ LOW PRIORITY** (Budouc√≠ features):
8. **NanobanaProvider** - Image generation pro PRO+ tier
9. **VeoProvider** - Video generation pro ULTIMATE tier
10. **structlog** - Lep≈°√≠ logging (kosmetick√° zmƒõna)
11. **litellm gateway** - Multi-provider abstrakce (nen√≠ nutn√©)

### üèóÔ∏è ARCHITEKTONICK√ù ROZD√çL: Pl√°n vs Realita

**PL√ÅN v dokumentu:**
```
AIGateway (OOP Gateway Class)
    ‚îú‚îÄ‚îÄ GeminiProvider
    ‚îú‚îÄ‚îÄ PerplexityProvider
    ‚îú‚îÄ‚îÄ NanobanaProvider
    ‚îî‚îÄ‚îÄ CostTracker
```

**REALITA v k√≥du:**
```
Factory Functions (Funkcion√°ln√≠ p≈ô√≠stup)
    ‚îú‚îÄ‚îÄ get_text_provider() ‚Üí GeminiProvider
    ‚îî‚îÄ‚îÄ get_research_provider() ‚Üí PerplexityProvider

P≈ô√≠m√© pou≈æit√≠ provider≈Ø bez gateway layer
```

**Z√°vƒõr:** K√≥d funguje dob≈ôe s factory pattern p≈ô√≠stupem. Nen√≠ nutnƒõ pot≈ôeba vytv√°≈ôet OOP Gateway t≈ô√≠du, ale **CostTracker** a **AICache** jsou kritick√© pro produkƒçn√≠ pou≈æit√≠.

---

*Tento dokument je SELF-CONTAINED - obsahuje v≈°echny informace o AI integrac√≠ch.*

---

## üìÇ P≈òESN√Å STRUKTURA SOUBOR≈Æ A K√ìDU

### Skuteƒçn√° slo≈æka `providers/`

```bash
$ ls -lh apps/ai_gateway/providers/
total 52
-rw-r--r-- 1 root root  476 Dec 15 07:27 __init__.py
-rw-r--r-- 1 root root 4686 Dec 16 07:22 base.py
-rw-r--r-- 1 root root 4364 Dec 16 08:00 gemini.py
-rw-r--r-- 1 root root 5842 Dec 16 08:07 perplexity.py
```

### `__init__.py` (476 byt≈Ø) - Factory Functions

```python
"""Factory functions for AI providers."""
from apps.ai_gateway.providers.base import AIProvider
from apps.ai_gateway.providers.gemini import GeminiProvider
from apps.ai_gateway.providers.perplexity import PerplexityProvider

def get_text_provider() -> AIProvider:
    """Get the default text generation provider (Gemini)."""
    return GeminiProvider()

def get_research_provider() -> AIProvider:
    """Get the web research provider (Perplexity)."""
    return PerplexityProvider()
```

### `base.py` (4,686 byt≈Ø) - Base Classes

```python
"""Base classes for AI providers."""
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Any

@dataclass
class GenerationResult:
    """Result from AI generation."""
    content: str | dict
    input_tokens: int
    output_tokens: int
    model: str
    provider: str
    raw_response: Any = None

class AIProvider(ABC):
    """Base class for all AI providers."""
    
    @abstractmethod
    def generate_text(self, prompt: str, **kwargs) -> GenerationResult:
        """Generate text from prompt."""
        pass
    
    @abstractmethod
    def generate_json(self, prompt: str, schema: dict) -> dict:
        """Generate structured JSON output."""
        pass
```

### `gemini.py` (4,364 byt≈Ø) - Gemini Provider

**Status:** ‚úÖ Plnƒõ funkƒçn√≠

```python
"""Google Gemini provider for text generation."""
import logging
import google.genai as genai
from django.conf import settings

from apps.ai_gateway.providers.base import AIProvider, GenerationResult

logger = logging.getLogger(__name__)

class GeminiProvider(AIProvider):
    """Gemini 1.5 Pro provider."""
    
    def __init__(self):
        self.client = genai.Client(api_key=settings.GEMINI_API_KEY)
        self.model = "gemini-1.5-pro-002"
    
    def generate_text(self, prompt: str, max_tokens: int = 4096, **kwargs) -> GenerationResult:
        """Generate text using Gemini."""
        response = self.client.models.generate_content(
            model=self.model,
            contents=prompt,
            config=genai.types.GenerateContentConfig(
                max_output_tokens=max_tokens,
            )
        )
        
        return GenerationResult(
            content=response.text,
            input_tokens=response.usage_metadata.prompt_token_count,
            output_tokens=response.usage_metadata.candidates_token_count,
            model=self.model,
            provider="gemini",
            raw_response=response,
        )
    
    def generate_json(self, prompt: str, schema: dict) -> dict:
        """Generate structured JSON."""
        # Implementation with JSON mode
        ...
```

### `perplexity.py` (5,842 byt≈Ø) - Perplexity Provider

**Status:** ‚úÖ Plnƒõ funkƒçn√≠

```python
"""Perplexity API provider for web search."""
import logging
import httpx
from django.conf import settings

from apps.ai_gateway.providers.base import AIProvider, GenerationResult

logger = logging.getLogger(__name__)

class PerplexityProvider(AIProvider):
    """Perplexity Sonar provider for web search."""
    
    def __init__(self):
        self.api_key = settings.PERPLEXITY_API_KEY
        self.base_url = "https://api.perplexity.ai"
        self.model = "llama-3.1-sonar-large-128k-online"
    
    def generate_text(self, prompt: str, **kwargs) -> GenerationResult:
        """Search the web and generate response."""
        with httpx.Client() as client:
            response = client.post(
                f"{self.base_url}/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json",
                },
                json={
                    "model": self.model,
                    "messages": [
                        {"role": "user", "content": prompt}
                    ],
                },
                timeout=60.0,
            )
            response.raise_for_status()
            data = response.json()
        
        return GenerationResult(
            content=data["choices"][0]["message"]["content"],
            input_tokens=data.get("usage", {}).get("prompt_tokens", 0),
            output_tokens=data.get("usage", {}).get("completion_tokens", 0),
            model=self.model,
            provider="perplexity",
            raw_response=data,
        )
    
    def generate_json(self, prompt: str, schema: dict) -> dict:
        """Generate structured JSON with web search."""
        # Adds schema instructions to prompt
        result = self.generate_text(prompt + "\n\nReturn ONLY valid JSON.")
        return json.loads(result.content)
```

### `models.py` - AIJob Model (NE PromptTemplate!)

**Status:** ‚úÖ Existuje pro job tracking

```python
"""AI Gateway models."""
from django.db import models
from apps.core.models import BaseModel

class JobStatus(models.TextChoices):
    PENDING = 'pending', 'Pending'
    PROCESSING = 'processing', 'Processing'
    COMPLETED = 'completed', 'Completed'
    FAILED = 'failed', 'Failed'
    CANCELLED = 'cancelled', 'Cancelled'

class JobType(models.TextChoices):
    SCRAPE_DNA = 'scrape_dna', 'Scrape Company DNA'
    GENERATE_PERSONAS = 'generate_personas', 'Generate Personas'
    GENERATE_TOPICS = 'generate_topics', 'Generate Topics'
    GENERATE_BLOGPOST = 'generate_blogpost', 'Generate Blog Post'
    GENERATE_SOCIAL = 'generate_social', 'Generate Social Posts'
    GENERATE_IMAGE = 'generate_image', 'Generate Image'
    GENERATE_VIDEO = 'generate_video', 'Generate Video'

class AIJob(BaseModel):
    """Tracks AI generation jobs with Celery integration."""
    company = models.ForeignKey('companies.Company', on_delete=models.CASCADE)
    created_by = models.ForeignKey('users.User', on_delete=models.SET_NULL, null=True)
    
    job_type = models.CharField(max_length=30, choices=JobType.choices)
    status = models.CharField(max_length=20, choices=JobStatus.choices)
    
    input_data = models.JSONField(default=dict)
    output_data = models.JSONField(default=dict)
    
    error_message = models.TextField(blank=True)
    error_details = models.JSONField(default=dict)
    
    started_at = models.DateTimeField(null=True, blank=True)
    completed_at = models.DateTimeField(null=True, blank=True)
    
    retry_count = models.IntegerField(default=0)
    max_retries = models.IntegerField(default=3)
    
    celery_task_id = models.CharField(max_length=255, blank=True)
    priority = models.IntegerField(default=5)
    
    tokens_used = models.IntegerField(default=0)
    generation_time_seconds = models.FloatField(null=True, blank=True)
```

### `services.py` - Business Logic (s hardcoded prompty!)

**Status:** ‚úÖ Funguje, ale prompty jsou hardcoded

```python
"""AI Gateway services."""
import logging
from apps.ai_gateway.providers import get_text_provider, get_research_provider

logger = logging.getLogger(__name__)

def scrape_company_dna(*, website: str, company_name: str) -> dict:
    """Scrape company DNA using Perplexity."""
    provider = get_research_provider()
    
    # ‚ùå HARDCODED PROMPT (mƒõl by b√Ωt v DB jako PromptTemplate!)
    prompt = f"""Research the company "{company_name}" with website {website}.

Find and return comprehensive information about:

1. **Mission & Vision**
   - Company mission statement
   - Company vision
   - Core purpose

2. **Values & Culture**
   - Core company values
   - Company culture aspects

3. **Target Audience**
   - Primary customer segments
   - Customer pain points
   - Customer desires/goals

4. **Business Details**
   - Industry/niche
   - Main products or services
   - Unique selling proposition (USP)

5. **Brand Voice**
   - Communication style (formal vs casual)
   - Tone (serious vs playful)
   - Key messaging themes

6. **Competitors**
   - Main competitors in the market

Be thorough and accurate. If information is not available, indicate "Not found".
"""
    
    # ‚ùå HARDCODED SCHEMA (mƒõlo by b√Ωt v PromptTemplate!)
    schema = {
        'mission': 'string - Company mission statement',
        'vision': 'string - Company vision',
        'values': ['string - Core value'],
        'target_audience': 'string - Description',
        'audience_pain_points': ['string - Pain point'],
        'audience_desires': ['string - Desire/goal'],
        'industry': 'string - Industry/niche',
        'products_services': ['string - Product or service'],
        'usp': 'string - Unique selling proposition',
        'tone_formal_casual': 'number 0-100',
        'tone_serious_playful': 'number 0-100',
        'content_themes': ['string - Content theme'],
        'competitors': ['string - Competitor name'],
    }
    
    result = provider.generate_json(prompt, schema)
    
    # Add defaults for missing fields
    defaults = {
        'mission': '', 'vision': '', 'values': [],
        'target_audience': '', 'audience_pain_points': [],
        'audience_desires': [], 'industry': '',
        'products_services': [], 'usp': '',
        'tone_formal_casual': 50, 'tone_serious_playful': 50,
        'content_themes': [], 'competitors': [],
    }
    
    for key, default in defaults.items():
        if key not in result or result[key] is None:
            result[key] = default
    
    return result


def generate_personas(*, company_dna: dict, count: int = 6) -> list[dict]:
    """Generate personas based on company DNA."""
    provider = get_text_provider()
    
    tone_formality = 'Casual' if company_dna.get('tone_formal_casual', 50) > 50 else 'Formal'
    tone_mood = 'Playful' if company_dna.get('tone_serious_playful', 50) > 50 else 'Serious'
    
    # ‚ùå DAL≈†√ç HARDCODED PROMPT!
    prompt = f"""Create {count} unique fictional author personas for content creation.

Company Information:
- Name: {company_dna.get('name', 'Unknown')}
- Industry: {company_dna.get('industry', 'General')}
- Mission: {company_dna.get('mission', 'Not specified')}
- Vision: {company_dna.get('vision', 'Not specified')}
- Values: {', '.join(company_dna.get('values', []))}
- Target Audience: {company_dna.get('target_audience', 'General audience')}
- USP: {company_dna.get('usp', 'Not specified')}
- Tone: {tone_formality}, {tone_mood}

Requirements for each persona:
1. **Unique Identity**: Distinct name and background
2. **Psychology**: Jung archetype and MBTI type that align with brand
3. **Personal Values**: 3-5 values that resonate with the company
4. **Writing Style**: Specific vocabulary level, sentence style, formality
5. **Visual Style**: Description for image generation
6. **Expertise**: 3-5 topics they're experts in

Make personas diverse but all aligned with the company's brand voice.
Include a mix of archetypes to cover different content angles.

Jung Archetypes: innocent, everyman, hero, outlaw, explorer, creator, ruler, 
magician, lover, caregiver, jester, sage

MBTI types: INTJ, INTP, ENTJ, ENTP, INFJ, INFP, ENFJ, ENFP, ISTJ, ISFJ, 
ESTJ, ESFJ, ISTP, ISFP, ESTP, ESFP
"""
    
    # ‚ùå HARDCODED SCHEMA
    schema = {
        'personas': [
            {
                'name': 'string - Full name',
                'bio': 'string - 2-3 sentence biography',
                'archetype': 'string - Jung archetype (lowercase)',
                'mbti': 'string - MBTI type (4 letters uppercase)',
                'values': ['string - Personal value'],
                'frustrations': ['string - What frustrates them'],
                'vocabulary_level': 'string - simple|professional|academic',
                # ... v√≠ce fields
            }
        ]
    }
    
    result = provider.generate_json(prompt, schema)
    return result['personas']
```

---

## üéØ KL√çƒåOV√â ZJI≈†TƒöN√ç

### ‚úÖ Co funguje v√Ωbornƒõ:
1. **Provider implementace** - GeminiProvider a PerplexityProvider jsou solidn√≠
2. **Factory pattern** - ƒåist√Ω, jednoduch√Ω p≈ô√≠stup bez zbyteƒçn√© abstrakce
3. **AIJob model** - Dobr√Ω z√°klad pro async job tracking s Celery
4. **Token tracking** - Data jsou k dispozici z API responses

### ‚ùå Nejvƒõt≈°√≠ probl√©my:
1. **Hardcoded prompty** - V≈°echny prompty jsou v `services.py`, ne v DB
   - Nelze upravovat bez code deploy
   - ≈Ω√°dn√© verzov√°n√≠ nebo A/B testing
   - Content mana≈æer nem≈Ø≈æe upravit
   
2. **≈Ω√°dn√Ω cost tracking** - I kdy≈æ m√°me `tokens_used` v `AIJob`, nen√≠ agregace
   - Chyb√≠ monthly summary per company
   - Nen√≠ billing integration
   
3. **≈Ω√°dn√Ω caching** - Opakovan√© requesty jdou znovu na API
   - Zbyteƒçn√© n√°klady
   - Pomalej≈°√≠ response

### üí° Quick Wins:
1. **AICache** - Implementace za 1-2 hodiny, okam≈æit√° √∫spora
2. **CostTracker** - Data u≈æ m√°me, jen p≈ôidat persistov√°n√≠
3. **PromptTemplate model** - Umo≈æn√≠ non-tech editaci prompt≈Ø

---

*Tento dokument nyn√≠ obsahuje KOMPLETN√ç informace o pl√°novan√© architektu≈ôe I skuteƒçn√©m stavu implementace.*
