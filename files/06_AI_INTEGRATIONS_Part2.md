def generate_prompt(
        self,
        message: str,
        persona,
        platform: str,
        industry: str | None = None,
    ) -> dict:
        """
        Generuje image prompt na z√°kladƒõ kontextu.
        """
        aspect_ratio = self.PLATFORM_ASPECTS.get(platform, '1:1')
        authenticity = self._determine_authenticity(industry or '')

        # Build base prompt
        prompt_parts = [
            f"[{aspect_ratio} aspect ratio]",
        ]
        
        # Add visual style from persona
        if persona.art_style_name:
            prompt_parts.append(f"[{persona.art_style_name} style]")
        
        if persona.color_palette:
            prompt_parts.append(f"[{persona.color_palette} color palette]")
        
        if persona.visual_atmosphere:
            prompt_parts.append(f"[{persona.visual_atmosphere} mood]")
        
        # Add authenticity modifiers
        if authenticity == 'high':
            prompt_parts.extend([
                "natural lighting",
                "authentic moment",
                "candid feel",
                "real environment",
            ])
        else:
            prompt_parts.extend([
                "professional photography",
                "studio quality",
                "polished composition",
                "editorial style",
            ])
        
        # Add content
        prompt_parts.append(message)
        
        # Add quality
        prompt_parts.append("high-quality, professional")
        
        full_prompt = ", ".join(prompt_parts)
        
        return {
            "prompt": full_prompt,
            "negative_prompt": "blurry, low quality, distorted, ugly, watermark, text, logo",
            "aspect_ratio": aspect_ratio,
            "authenticity_level": authenticity,
        }
    
    def _determine_authenticity(self, industry: str) -> str:
        """Urƒç√≠ √∫rove≈à authenticity podle industry."""
        industry_lower = industry.lower()
        
        for ind in self.HIGH_AUTHENTICITY_INDUSTRIES:
            if ind in industry_lower:
                return 'high'
        
        for ind in self.LOW_AUTHENTICITY_INDUSTRIES:
            if ind in industry_lower:
                return 'low'
        
        return 'medium'

```

---

## 6. VIDEO GENERATION (VEO 3)

### Provider Implementation

```python
# apps/ai_gateway/providers/veo.py
import httpx
import asyncio
import structlog

logger = structlog.get_logger(__name__)

class VeoProvider:
    """
    Veo 3 video generation provider.
    ULTIMATE tier only.
    """
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.veo.google"
    
    async def generate_video(
        self,
        prompt: str,
        *,
        duration: int = 6,  # 6-10 seconds
        aspect_ratio: str = "16:9",
        style: str | None = None,
    ) -> dict:
        """
        Generuje kr√°tk√© video.
        """
        full_prompt = prompt
        if style:
            full_prompt = f"{prompt}, {style} style"
        
        async with httpx.AsyncClient() as client:
            # Start generation
            response = await client.post(
                f"{self.base_url}/v1/videos/generate",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                },
                json={
                    "prompt": full_prompt,
                    "duration_seconds": duration,
                    "aspect_ratio": aspect_ratio,
                    "model": "veo-3",
                },
                timeout=30.0,
            )
            response.raise_for_status()
            job = response.json()
            
            # Poll for completion
            job_id = job["id"]
            max_attempts = 60  # 5 minutes max
            
            for _ in range(max_attempts):
                status_response = await client.get(
                    f"{self.base_url}/v1/videos/{job_id}",
                    headers={"Authorization": f"Bearer {self.api_key}"},
                )
                status_response.raise_for_status()
                status = status_response.json()
                
                if status["status"] == "completed":
                    return {
                        "url": status["video_url"],
                        "thumbnail_url": status.get("thumbnail_url"),
                        "duration": status["duration"],
                        "prompt_used": full_prompt,
                    }
                elif status["status"] == "failed":
                    raise Exception(f"Video generation failed: {status.get('error')}")
                
                await asyncio.sleep(5)  # Poll every 5 seconds
            
## 6. VIDEO GENERATION (VEO 3)

### Provider Implementation

```python
# apps/ai_gateway/providers/veo.py
import httpx
import asyncio
import structlog

logger = structlog.get_logger(__name__)

class VeoProvider:
    """
    Veo 3 video generation provider.
    ULTIMATE tier only.
    """
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.veo.google"
    
    async def generate_video(
        self,
        prompt: str,
        *,
        duration: int = 6,  # 6-10 seconds
        aspect_ratio: str = "16:9",
        style: str | None = None,
    ) -> dict:
        """
        Generuje kr√°tk√© video.
        """
        full_prompt = prompt
        if style:
            full_prompt = f"{prompt}, {style} style"
        
        async with httpx.AsyncClient() as client:
            # Start generation
            response = await client.post(
                f"{self.base_url}/v1/videos/generate",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                },
                json={
                    "prompt": full_prompt,
                    "duration_seconds": duration,
                    "aspect_ratio": aspect_ratio,
                    "model": "veo-3",
                },
                timeout=30.0,
            )
            response.raise_for_status()
            job = response.json()
            
            # Poll for completion
            job_id = job["id"]
            max_attempts = 60  # 5 minutes max
            
            for _ in range(max_attempts):
                status_response = await client.get(
                    f"{self.base_url}/v1/videos/{job_id}",
                    headers={"Authorization": f"Bearer {self.api_key}"},
                )
                status_response.raise_for_status()
                status = status_response.json()
                
                if status["status"] == "completed":
                    return {
                        "url": status["video_url"],
                        "thumbnail_url": status.get("thumbnail_url"),
                        "duration": status["duration"],
                        "prompt_used": full_prompt,
                    }
                elif status["status"] == "failed":
                    raise Exception(f"Video generation failed: {status.get('error')}")
                
                await asyncio.sleep(5)  # Poll every 5 seconds
            
            raise TimeoutError("Video generation timed out")
```

**Aktu√°ln√≠ stav implementace:**

- ‚ùå **VeoProvider NEEXISTUJE** - Nen√≠ implementov√°n, video generation nen√≠ aktivn√≠
- ‚úÖ **API KEY existuje** - `VEO_API_KEY` je v `.env`, ale provider nen√≠ spu≈°tƒõn√Ω
- ‚ùå **Video generation** - Nen√≠ implementov√°na ≈æ√°dn√° ƒç√°st video generov√°n√≠
- ‚ùå **Job polling system** - Nen√≠ implementov√°n asynchronn√≠ polling system
- ‚ùå **Video storage** - Nen√≠ implementov√°no storage pro vygenerovan√° videa
- ‚ö†Ô∏è **Pl√°novan√° feature** - Video generation je na roadmapƒõ pro ULTIMATE tier

**Status:**

```
üî¥ NEN√ç IMPLEMENTOV√ÅNO
üìã Pl√°nov√°no pro budouc√≠ verzi
üí∞ Souƒç√°st ULTIMATE subscription tier (nejvy≈°≈°√≠ tier)
‚è±Ô∏è Vy≈æaduje komplexn√≠ polling system a video storage
```

Video generation je nejslo≈æitƒõj≈°√≠ a nejdra≈æ≈°√≠ feature, kter√° vy≈æaduje:

1. Implementaci VeoProvider s async polling
2. Video storage (S3/specialized video CDN)
3. Feature gating - pouze ULTIMATE tier
4. UI pro video generation a preview
5. Cost tracking (velmi drah√© - $0.05/sekunda)
6. Queue system pro dlouh√© video jobs

---

## 7. PROMPT ENGINEERING

### Prompt Templates

```python
# Ulo≈æeno v datab√°zi jako PromptTemplate

**Aktu√°ln√≠ stav implementace:**
- ‚ùå **`PromptTemplate` DB model NEEXISTUJE** - Tento model nen√≠ implementov√°n
- ‚úÖ **`AIJob` model EXISTUJE** - M√≠sto PromptTemplate existuje model pro tracking AI job≈Ø
- ‚ùå **Template management** - Nen√≠ syst√©m pro spr√°vu a verzov√°n√≠ prompt templates
- ‚ö†Ô∏è **Prompty jsou HARDCODED** - V≈°echny prompty jsou p≈ô√≠mo v service funkc√≠ch, ne v DB
- ‚ùå **Jinja2 templating** - Nen√≠ pou≈æ√≠v√°n pro dynamic prompt rendering
- ‚ùå **Template versioning** - Nen√≠ syst√©m verzov√°n√≠ (V1, V2, V3...)
- ‚ùå **Template types** - Nen√≠ kategorizace podle typu (persona, topic, blogpost, social_post)

**Co SKUTEƒåNƒö existuje - `AIJob` model:**

M√≠sto `PromptTemplate` modelu pro ≈°ablony, aplikace m√° `AIJob` model pro tracking AI operac√≠:

```python
# apps/ai_gateway/models.py (skuteƒçn√Ω k√≥d)
from django.db import models
from apps.core.models import BaseModel

class JobStatus(models.TextChoices):
    """AI job status choices."""
    PENDING = 'pending', 'Pending'
    PROCESSING = 'processing', 'Processing'
    COMPLETED = 'completed', 'Completed'
    FAILED = 'failed', 'Failed'
    CANCELLED = 'cancelled', 'Cancelled'

class JobType(models.TextChoices):
    """AI job type choices."""
    SCRAPE_DNA = 'scrape_dna', 'Scrape Company DNA'
    GENERATE_PERSONAS = 'generate_personas', 'Generate Personas'
    GENERATE_TOPICS = 'generate_topics', 'Generate Topics'
    GENERATE_BLOGPOST = 'generate_blogpost', 'Generate Blog Post'
    GENERATE_SOCIAL = 'generate_social', 'Generate Social Posts'
    GENERATE_IMAGE = 'generate_image', 'Generate Image'
    GENERATE_VIDEO = 'generate_video', 'Generate Video'

class AIJob(BaseModel):
    """
    Tracks AI generation jobs.
    
    CRITICAL: AIJob belongs to COMPANY (content tenant), not Organization!
    """
    company = models.ForeignKey('companies.Company', on_delete=models.CASCADE)
    created_by = models.ForeignKey('users.User', on_delete=models.SET_NULL, null=True)
    
    # Job identification
    job_type = models.CharField(max_length=30, choices=JobType.choices)
    status = models.CharField(max_length=20, choices=JobStatus.choices, default=JobStatus.PENDING)
    
    # Data
    input_data = models.JSONField(default=dict)
    output_data = models.JSONField(default=dict, blank=True)
    
    # Error tracking
    error_message = models.TextField(blank=True)
    error_details = models.JSONField(default=dict, blank=True)
    
    # Timing
    started_at = models.DateTimeField(null=True, blank=True)
    completed_at = models.DateTimeField(null=True, blank=True)
    
    # Retry logic
    retry_count = models.IntegerField(default=0)
    max_retries = models.IntegerField(default=3)
    
    # Celery integration
    celery_task_id = models.CharField(max_length=255, blank=True)
    priority = models.IntegerField(default=5)
    
    # Usage tracking
    tokens_used = models.IntegerField(default=0)
    generation_time_seconds = models.FloatField(null=True, blank=True)
    
    def mark_processing(self):
        """Mark job as processing."""
        self.status = JobStatus.PROCESSING
        self.started_at = timezone.now()
        self.save()
    
    def mark_completed(self, output_data: dict, tokens_used: int = 0):
        """Mark job as completed."""
        self.status = JobStatus.COMPLETED
        self.output_data = output_data
        self.completed_at = timezone.now()
        self.tokens_used = tokens_used
        self.save()
    
    def mark_failed(self, error_message: str, error_details: dict = None):
        """Mark job as failed."""
        self.status = JobStatus.FAILED
        self.error_message = error_message
        self.error_details = error_details or {}
        self.completed_at = timezone.now()
        self.save()
```

**Kl√≠ƒçov√© vlastnosti `AIJob` modelu:**

- ‚úÖ **Job tracking** - Sleduje v≈°echny AI operace (scraping, generation)
- ‚úÖ **Status management** - PENDING ‚Üí PROCESSING ‚Üí COMPLETED/FAILED
- ‚úÖ **Celery integration** - Ukl√°d√° `celery_task_id` pro async tracking
- ‚úÖ **Retry logic** - Automatick√© retry s max 3 pokusy
- ‚úÖ **Usage tracking** - Sleduje `tokens_used` a `generation_time_seconds`
- ‚úÖ **Error handling** - Ukl√°d√° error messages a details
- ‚úÖ **Company-scoped** - Pat≈ô√≠ k Company, ne Organization (multi-tenancy)

**Skuteƒçn√© pou≈æit√≠ v aplikaci:**

```python
# Services pou≈æ√≠vaj√≠ hardcoded prompty, ne DB templates:

def scrape_company_dna(*, website: str, company_name: str) -> dict:
    """Scrape company DNA using Perplexity."""
    provider = get_research_provider()
    
    # ‚ùå Prompt je HARDCODED, ne z DB
    prompt = f'''Research the company "{company_name}" with website {website}.

Find and return comprehensive information about:

1. **Mission & Vision**
   - Company mission statement
   - Company vision
   
2. **Values & Culture**
   - Core company values
   
3. **Target Audience**
   - Primary customer segments
   
... (full prompt hardcoded here)
'''
    
    schema = {
        'mission': 'string - Company mission',
        'vision': 'string - Company vision',
        'values': ['string - Core value'],
        # ... schema je taky hardcoded
    }
    
    result = provider.generate_json(prompt, schema)
    return result


def generate_personas(*, company_dna: dict, count: int = 6) -> list[dict]:
    """Generate personas based on company DNA."""
    provider = get_text_provider()
    
    # ‚ùå Prompt je opƒõt HARDCODED
    prompt = f'''Create {count} unique fictional author personas.

Company Information:
- Name: {company_dna.get('name')}
- Industry: {company_dna.get('industry')}
- Mission: {company_dna.get('mission')}

Requirements for each persona:
1. Unique Identity
2. Psychology: Jung archetype and MBTI
3. Personal Values: 3-5 values
... (full prompt hardcoded)
'''
    
    schema = {
        'personas': [
            {
                'name': 'string - Full name',
                'bio': 'string - Biography',
                'archetype': 'string - Jung archetype',
                'mbti': 'string - MBTI type',
                # ... schema hardcoded
            }
        ]
    }
    
    result = provider.generate_json(prompt, schema)
    return result['personas']
```

**Proƒç je to probl√©m:**

- üîÑ **Tƒõ≈æk√° √∫dr≈æba** - Zmƒõna promptu vy≈æaduje code deploy, ne DB update
- üìù **≈Ω√°dn√© verzov√°n√≠** - Nelze A/B testovat r≈Øzn√© verze prompt≈Ø
- üîç **≈Ω√°dn√Ω audit trail** - Nen√≠ historie zmƒõn prompt≈Ø
- üë• **Vy≈æaduje program√°tora** - Content mana≈æer nem≈Ø≈æe upravit prompty bez code zmƒõny
- üéØ **≈Ω√°dn√° optimalizace** - Nelze trackovat kter√© prompt verze funguj√≠ nejl√©pe

**Co je pot≈ôeba implementovat:**

1. ‚úÖ Vytvo≈ôit `PromptTemplate` model v Django
2. ‚úÖ P≈ôidat fields: `code`, `name`, `template_type`, `system_prompt`, `user_prompt_template`, `temperature`, `max_tokens`, `version`
3. ‚úÖ Migrovat v≈°echny hardcoded prompty do datab√°ze
4. ‚úÖ Implementovat Jinja2 rendering pro variables (`{{ company.name }}`, `{% for persona in personas %}`)
5. ‚úÖ Vytvo≈ôit management commands pro import/export templates
6. ‚úÖ P≈ôidat versioning system (V1, V2, V3...) s mo≈ænost√≠ A/B testingu
7. ‚úÖ UI pro editaci templates v admin rozhran√≠ nebo custom UI
8. ‚úÖ Integrovat do services - m√≠sto hardcoded prompt≈Ø naƒç√≠tat z DB

# =============================================================================

# PERSONA GENERATION

# =============================================================================

PERSONA_GEN_V1 = {
    "code": "PERSONA_GEN_V1",
    "name": "Persona Generation v1",
    "template_type": "persona",
    "system_prompt": """Jsi expert na tvorbu brand person a obsahovou strategii pro ƒçesk√© firmy.
Tv√Ωm √∫kolem je vytvo≈ôit 6 unik√°tn√≠ch, realistick√Ωch a diverzifikovan√Ωch person.

Ka≈æd√° persona mus√≠ b√Ωt:

1. Unik√°tn√≠ v kombinaci archetypu, MBTI a perspektivy
2. Relevantn√≠ pro dan√Ω obor podnik√°n√≠
3. Schopn√° komunikovat s c√≠lovou skupinou firmy

D≈ÆLE≈ΩIT√â: Nikdy neopakuj stejnou kombinaci Jungova archetypu nebo MBTI typu!""",

    "user_prompt_template": """Vytvo≈ô 6 unik√°tn√≠ch person pro firmu:

=== INFORMACE O FIRMƒö ===
N√°zev: {{ company.name }}
Obor: {{ company.business_field }}
Produkt/slu≈æba: {{ company.product_type }}

=== C√çLOV√Å SKUPINA ===
{{ company.company_dna.target_audience | default('Nespecifikov√°no') }}

=== PO≈ΩADAVKY ===

- 6 R≈ÆZN√ùCH Jungov√Ωch archetyp≈Ø
- 6 R≈ÆZN√ùCH MBTI typ≈Ø
- R≈Øzn√© √∫rovnƒõ hierarchie

Vra≈• JSON s polem "personas" obsahuj√≠c√≠m 6 person.""",

    "temperature": 0.8,
    "max_tokens": 8192,
}

# =============================================================================

# TOPIC GENERATION

# =============================================================================

TOPIC_GEN_V1 = {
    "code": "TOPIC_GEN_V1",
    "name": "Topic Generation v1",
    "template_type": "topic",
    "system_prompt": """Jsi expert na obsahovou strategii a SEO pro ƒçesk√© firmy.
Vytv√°≈ô√≠≈° promy≈°len√© obsahov√© pl√°ny t√©mat pro blogov√© p≈ô√≠spƒõvky.

Ka≈æd√© t√©ma mus√≠:

1. B√Ωt relevantn√≠ pro obor firmy
2. M√≠t jasn√Ω SEO potenci√°l
3. B√Ωt p≈ôi≈ôazeno konkr√©tn√≠ personƒõ""",

    "user_prompt_template": """Vytvo≈ô {{ posts_count }} t√©mat pro mƒõs√≠c {{ month }}/{{ year }}:

=== FIRMA ===
N√°zev: {{ company.name }}
Obor: {{ company.business_field }}

=== PERSONY ===
{% for persona in personas %}

- {{ persona.character_name }} ({{ persona.jung_archetype }})
{% endfor %}

=== PRAVIDLA ===

- Rozdƒõl t√©mata rovnomƒõrnƒõ mezi persony
- Napl√°nuj t√©mata p≈ôes cel√Ω mƒõs√≠c

Vra≈• JSON s polem "topics".""",

    "temperature": 0.7,
    "max_tokens": 4096,
}

# =============================================================================

# BLOGPOST GENERATION

# =============================================================================

BLOGPOST_GEN_V1 = {
    "code": "BLOGPOST_GEN_V1",
    "name": "Blogpost Generation v1",
    "template_type": "blogpost",
    "system_prompt": """Jsi zku≈°en√Ω copywriter. P√≠≈°e≈° jako konkr√©tn√≠ persona - s jej√≠m hlasem, slovn√≠kem a zp≈Øsobem argumentace.

Blogpost mus√≠ obsahovat:

1. Magnetick√Ω titulek s focus keyword
2. Strukturovan√© sekce (intro, body, conclusion)
3. FAQ sekci
4. Key takeaways
5. 1500-2500 slov""",

    "user_prompt_template": """Napi≈° blogpost na t√©ma:

=== T√âMA ===
Titulek: {{ topic.title }}
Popis: {{ topic.description }}
Focus keyword: {{ topic.focus_keyword }}

=== PERSONA ===
Jm√©no: {{ persona.character_name }}
Archetyp: {{ persona.jung_archetype }}
MBTI: {{ persona.mbti_type }}
Slovn√≠ z√°soba: {{ persona.vocabulary_level }}
Obl√≠ben√© fr√°ze: {{ persona.favorite_phrases }}
Typick√Ω z√°vƒõr: {{ persona.unique_signature_ending }}

=== FIRMA ===
{{ company.name }} - {{ company.business_field }}

Vra≈• strukturovan√Ω JSON.""",

    "temperature": 0.7,
    "max_tokens": 12000,
}

# =============================================================================

# SOCIAL POST GENERATION

# =============================================================================

SOCIAL_POST_GEN_V1 = {
    "code": "SOCIAL_POST_GEN_V1",
    "name": "Social Post Generation v1",
    "template_type": "social_post",
    "system_prompt": """Jsi expert na soci√°ln√≠ s√≠tƒõ a vir√°ln√≠ obsah.
Transformuje≈° blogposty do p≈ô√≠spƒõvk≈Ø pro konkr√©tn√≠ platformy.""",

    "user_prompt_template": """Vytvo≈ô p≈ô√≠spƒõvek pro {{ platform }}:

=== BLOGPOST ===
Titulek: {{ blogpost.title }}
Key takeaways:
{% for takeaway in blogpost.key_takeaways %}

- {{ takeaway }}
{% endfor %}

=== PERSONA ===
{{ persona.character_name }} - {{ persona.jung_archetype }}
Obl√≠ben√© fr√°ze: {{ persona.favorite_phrases }}

=== PLATFORMA: {{ platform | upper }} ===
{% if platform == 'instagram' %}
Max d√©lka: 2200 znak≈Ø
5-15 hashtag≈Ø
Hook v prvn√≠ vƒõtƒõ
{% elif platform == 'linkedin' %}
Profesion√°ln√≠ t√≥n
3-5 hashtag≈Ø
Hook v prvn√≠ch 2 ≈ô√°dc√≠ch
{% elif platform == 'twitter' %}
Max 280 znak≈Ø
1-2 hashtagy
{% endif %}

Vra≈• JSON s textContent, hashtags, ctaText.""",

    "temperature": 0.75,
    "max_tokens": 2048,
}

```

---

## 8. COST TRACKING

### Cost Tracker

```python
# apps/ai_gateway/cost_tracker.py
from decimal import Decimal
from django.core.cache import cache
from django.utils import timezone

# Ceny za 1000 token≈Ø (USD)
COST_PER_1K_TOKENS = {
    'gemini': {
        'input': Decimal('0.00025'),
        'output': Decimal('0.0005'),
    },
    'perplexity': {
        'input': Decimal('0.001'),
        'output': Decimal('0.001'),
    },
}

# Ceny za obr√°zek/video
COST_PER_IMAGE = {
    'nanobana': Decimal('0.02'),
}

COST_PER_VIDEO_SECOND = {
    'veo': Decimal('0.05'),
}

class CostTracker:
    def __init__(self):
        self.cache_prefix = "ai_cost"
    
    async def track(
        self,
        organization,
        provider: str,
        input_tokens: int,
        output_tokens: int,
    ) -> Decimal:
        """Sleduje cost za text generov√°n√≠."""
        costs = COST_PER_1K_TOKENS.get(provider, {})
        
        input_cost = (Decimal(input_tokens) / 1000) * costs.get('input', Decimal('0'))
        output_cost = (Decimal(output_tokens) / 1000) * costs.get('output', Decimal('0'))
        total_cost = input_cost + output_cost
        
        # Update cache counter
        cache_key = f"{self.cache_prefix}:{organization.id}:{timezone.now().strftime('%Y-%m')}"
        current = cache.get(cache_key, Decimal('0'))
        cache.set(cache_key, current + total_cost, timeout=60*60*24*31)  # 31 days
        
        # Update usage record in DB (async)
        from apps.billing.tasks import update_usage_record
        update_usage_record.delay(
            str(organization.id),
            tokens=input_tokens + output_tokens,
            cost=float(total_cost),
        )
        
        return total_cost
    
    async def track_image(
        self,
        organization,
        provider: str,
    ) -> Decimal:
        """Sleduje cost za image generov√°n√≠."""
        cost = COST_PER_IMAGE.get(provider, Decimal('0'))
        
        cache_key = f"{self.cache_prefix}:{organization.id}:{timezone.now().strftime('%Y-%m')}"
        current = cache.get(cache_key, Decimal('0'))
        cache.set(cache_key, current + cost, timeout=60*60*24*31)
        
        from apps.billing.tasks import update_usage_record
        update_usage_record.delay(
            str(organization.id),
            images=1,
            cost=float(cost),
        )
        
        return cost
    
    def get_monthly_cost(self, organization) -> Decimal:
        """Z√≠sk√° aktu√°ln√≠ mƒõs√≠ƒçn√≠ cost."""
## 8. COST TRACKING

### Cost Tracker

```python
# apps/ai_gateway/cost_tracker.py
from decimal import Decimal
from django.core.cache import cache
from django.utils import timezone

# Ceny za 1000 token≈Ø (USD)
COST_PER_1K_TOKENS = {
    'gemini': {
        'input': Decimal('0.00025'),
        'output': Decimal('0.0005'),
    },
    'perplexity': {
        'input': Decimal('0.001'),
        'output': Decimal('0.001'),
    },
}

# Ceny za obr√°zek/video
COST_PER_IMAGE = {
    'nanobana': Decimal('0.02'),
}

COST_PER_VIDEO_SECOND = {
    'veo': Decimal('0.05'),
}

class CostTracker:
    def __init__(self):
        self.cache_prefix = "ai_cost"
    
    async def track(
        self,
        organization,
        provider: str,
        input_tokens: int,
        output_tokens: int,
    ) -> Decimal:
        """Sleduje cost za text generov√°n√≠."""
        costs = COST_PER_1K_TOKENS.get(provider, {})
        
        input_cost = (Decimal(input_tokens) / 1000) * costs.get('input', Decimal('0'))
        output_cost = (Decimal(output_tokens) / 1000) * costs.get('output', Decimal('0'))
        total_cost = input_cost + output_cost
        
        # Update cache counter
        cache_key = f"{self.cache_prefix}:{organization.id}:{timezone.now().strftime('%Y-%m')}"
        current = cache.get(cache_key, Decimal('0'))
        cache.set(cache_key, current + total_cost, timeout=60*60*24*31)  # 31 days
        
        # Update usage record in DB (async)
        from apps.billing.tasks import update_usage_record
        update_usage_record.delay(
            str(organization.id),
            tokens=input_tokens + output_tokens,
            cost=float(total_cost),
        )
        
        return total_cost
    
    async def track_image(
        self,
        organization,
        provider: str,
    ) -> Decimal:
        """Sleduje cost za image generov√°n√≠."""
        cost = COST_PER_IMAGE.get(provider, Decimal('0'))
        
        cache_key = f"{self.cache_prefix}:{organization.id}:{timezone.now().strftime('%Y-%m')}"
        current = cache.get(cache_key, Decimal('0'))
        cache.set(cache_key, current + cost, timeout=60*60*24*31)
        
        from apps.billing.tasks import update_usage_record
        update_usage_record.delay(
            str(organization.id),
            images=1,
            cost=float(cost),
        )
        
        return cost
    
    def get_monthly_cost(self, organization) -> Decimal:
        """Z√≠sk√° aktu√°ln√≠ mƒõs√≠ƒçn√≠ cost."""
        cache_key = f"{self.cache_prefix}:{organization.id}:{timezone.now().strftime('%Y-%m')}"
        return cache.get(cache_key, Decimal('0'))
```

**Aktu√°ln√≠ stav implementace:**

- ‚ùå **`CostTracker` t≈ô√≠da NEEXISTUJE** - Nen√≠ implementov√°na ≈æ√°dn√° centr√°ln√≠ cost tracking t≈ô√≠da
- ‚ùå **Cost tracking per provider** - Nen√≠ sledov√°n√≠ n√°klad≈Ø podle providera (gemini, perplexity)
- ‚ùå **Cache-based counters** - Nen√≠ implementov√°no ukl√°d√°n√≠ mƒõs√≠ƒçn√≠ch n√°klad≈Ø do cache
- ‚ùå **Integration s billing** - Nen√≠ propojen√≠ s `apps.billing.tasks.update_usage_record`
- ‚ùå **Cost constants** - Konstanty `COST_PER_1K_TOKENS`, `COST_PER_IMAGE`, `COST_PER_VIDEO_SECOND` nejsou definov√°ny
- ‚ùå **Monthly aggregation** - Nen√≠ funkce `get_monthly_cost()`
- ‚ö†Ô∏è **Token counts jsou k dispozici** - Gemini a Perplexity vracej√≠ `input_tokens` a `output_tokens` v response, ale nejsou sledov√°ny

**Skuteƒçn√Ω stav:**

```python
# Realita: ≈Ω√°dn√Ω cost tracking
# Token counts jsou dostupn√© v GenerationResult, ale nejsou sledov√°ny:

@dataclass
class GenerationResult:
    content: str
    input_tokens: int      # ‚úÖ K dispozici z API
    output_tokens: int     # ‚úÖ K dispozici z API
    model: str
    provider: str

# Ale nejsou nikam persistov√°ny ani agregov√°ny! ‚ùå
```

**Co je pot≈ôeba implementovat:**

1. ‚úÖ Vytvo≈ôit `CostTracker` t≈ô√≠du v `apps/ai_gateway/cost_tracker.py`
2. ‚úÖ Definovat cost constants pro v≈°echny providery
3. ‚úÖ Implementovat `track()` metodu pro text generation tracking
4. ‚úÖ Implementovat `track_image()` a `track_video()` metody
5. ‚úÖ Vytvo≈ôit `update_usage_record` Celery task v `apps.billing.tasks`
6. ‚úÖ Integrovat do v≈°ech provider vol√°n√≠ (GeminiProvider, PerplexityProvider)
7. ‚úÖ Vytvo≈ôit billing reports pro organizace
8. ‚úÖ P≈ôidat cost monitoring dashboard

---

## 9. CACHING & OPTIMIZATION

### Semantic Cache

```python
# apps/ai_gateway/cache.py
from django.core.cache import cache
import hashlib

class AICache:
    """Cache pro AI responses."""
    
    PREFIX = "ai_response"
    DEFAULT_TTL = 3600  # 1 hour
    
    @classmethod
    def get_key(cls, prompt: str, model: str) -> str:
        """Generuje cache key z promptu."""
        content = f"{model}:{prompt}"
        return f"{cls.PREFIX}:{hashlib.sha256(content.encode()).hexdigest()}"
    
    @classmethod
    def get(cls, prompt: str, model: str) -> str | None:
        """Z√≠sk√° cached response."""
        key = cls.get_key(prompt, model)
        return cache.get(key)
    
    @classmethod
    def set(cls, prompt: str, model: str, response: str, ttl: int = None):
        """Ulo≈æ√≠ response do cache."""
        key = cls.get_key(prompt, model)
        cache.set(key, response, ttl or cls.DEFAULT_TTL)
    
### Rate Limiting

```python
# apps/ai_gateway/rate_limiter.py
from django.core.cache import cache
import time

class AIRateLimiter:
    """Rate limiter pro AI API vol√°n√≠."""
    
    # Limity per provider per minute
    LIMITS = {
        'gemini': 60,
        'perplexity': 50,
        'nanobana': 10,
        'veo': 5,
    }
    
    @classmethod
    def check(cls, provider: str, organization_id: str) -> bool:
        """Kontroluje zda lze prov√©st vol√°n√≠."""
        key = f"rate_limit:{provider}:{organization_id}"
        current = cache.get(key, 0)
        limit = cls.LIMITS.get(provider, 60)
        return current < limit
    
    @classmethod
    def increment(cls, provider: str, organization_id: str):
        """Inkrementuje counter."""
        key = f"rate_limit:{provider}:{organization_id}"
        current = cache.get(key, 0)
        cache.set(key, current + 1, timeout=60)  # Reset every minute
    
---

## üìå QUICK REFERENCE

### Environment Variables

```bash
GEMINI_API_KEY=your-gemini-api-key
PERPLEXITY_API_KEY=your-perplexity-api-key
NANOBANA_API_KEY=your-nanobana-api-key
VEO_API_KEY=your-veo-api-key
```

### Usage Example

```python
from apps.ai_gateway.services import AIGateway
from apps.ai_gateway.models import PromptTemplate

gateway = AIGateway()

# Text generation
template = PromptTemplate.objects.get(code='BLOGPOST_GEN_V1')
result = await gateway.generate(
    prompt_template=template,
    variables={'topic': topic, 'persona': persona, 'company': company},
    organization=organization,
)

# Image generation
image = await gateway.generate_image(
    prompt="Professional business meeting in modern office",
    organization=organization,
    aspect_ratio="16:9",
)
```

**Aktu√°ln√≠ stav implementace pro QUICK REFERENCE:**

- ‚úÖ **Environment Variables** - V≈°echny 4 API keys jsou spr√°vnƒõ nakonfigurov√°ny v `.env`
- ‚ùå **AIGateway t≈ô√≠da** - NEEXISTUJE, m√≠sto toho se pou≈æ√≠vaj√≠ factory funkce
- ‚ùå **PromptTemplate model** - NEEXISTUJE, prompty jsou hardcoded
- ‚ùå **Usage example** - K√≥d v p≈ô√≠kladu NEFUNGUJE, proto≈æe `AIGateway()` t≈ô√≠da neexistuje

**Skuteƒçn√© pou≈æit√≠:**

```python
# Realita - funkcion√°ln√≠ factory pattern:
from apps.ai_gateway.providers import get_text_provider, get_research_provider

# Text generation (Gemini)
text_provider = get_text_provider()
result = await text_provider.generate_text(
    system_prompt="Jsi expert na...",
    user_prompt="Vytvo≈ô blogpost o...",
    temperature=0.7,
    max_tokens=4096,
)

# Research (Perplexity)
research_provider = get_research_provider()
company_info = await research_provider.search(
    query=f"informace o firmƒõ {domain}"
)
```

---

## üìä IMPLEMENTATION STATUS SUMMARY

### ‚úÖ CO JE IMPLEMENTOV√ÅNO (Funguje v produkci)

| Komponenta | Status | Detail |
|------------|--------|--------|
| **GeminiProvider** | ‚úÖ Funguje | Text generation pomoc√≠ Gemini 1.5 Pro |
| **PerplexityProvider** | ‚úÖ Funguje | Web search a company scraping |
| **API Keys** | ‚úÖ Nakonfigurov√°ny | V≈°echny 4 keys v `.env` |
| **GenerationResult dataclass** | ‚úÖ Existuje | Pro n√°vratov√© hodnoty |
| **Factory functions** | ‚úÖ Funguj√≠ | `get_text_provider()`, `get_research_provider()` |
| **`scrape_company_dna()`** | ‚úÖ Funguje | Kl√≠ƒçov√° funkce pro onboarding |
| **Async support** | ‚úÖ Funguje | V≈°echny providery jsou async |
| **Token counts** | ‚úÖ K dispozici | V response metadata |

### ‚ùå CO NEN√ç IMPLEMENTOV√ÅNO (Pouze pl√°n)

| Komponenta | D≈Øvod absence | Priorita |
|------------|---------------|----------|
| **AIGateway t≈ô√≠da** | Pou≈æ√≠v√° se funkcion√°ln√≠ p≈ô√≠stup m√≠sto OOP | üü° Medium |
| **CostTracker** | Nen√≠ sledov√°n√≠ n√°klad≈Ø | üî¥ High |
| **PromptTemplate model** | Prompty jsou hardcoded | üü° Medium |
| **AICache** | Nen√≠ caching AI responses | üî¥ High |
| **AIRateLimiter** | Nen√≠ rate limiting | üü° Medium |
| **NanobanaProvider** | Image generation nen√≠ aktivn√≠ | üü¢ Low |
| **VeoProvider** | Video generation nen√≠ aktivn√≠ | üü¢ Low |
| **ImageResult dataclass** | Nen√≠ pot≈ôeba bez image gen | üü¢ Low |
| **structlog** | Pou≈æ√≠v√° se standardn√≠ `logging` | üü¢ Low |
| **litellm** | Je v requirements, ale je zakomentovan√Ω | üü¢ Low |
| **tiktoken** | Nen√≠ pro p≈ôesn√© poƒç√≠t√°n√≠ token≈Ø | üü¢ Low |

### üéØ PRIORITY IMPLEMENTACE (Co implementovat jako prvn√≠)

**üî¥ HIGH PRIORITY** (Kritick√© pro produkci):

1. **CostTracker** - Sledov√°n√≠ n√°klad≈Ø per organizace, kritick√© pro billing
2. **AICache** - Sn√≠≈æen√≠ n√°klad≈Ø a latence, snadn√° win
3. **Error handling & retries** - Robustn√≠ handling API selh√°n√≠

**üü° MEDIUM PRIORITY** (Zlep≈°en√≠ architektury):
4. **PromptTemplate model** - Lep≈°√≠ spr√°va prompt≈Ø, verzov√°n√≠
5. **AIRateLimiter** - Ochrana p≈ôed p≈ôekroƒçen√≠m limit≈Ø
6. **AIGateway t≈ô√≠da** - Centralizace logiky (nebo ponechat factory pattern)
7. **Monitoring & metrics** - Sledov√°n√≠ vyu≈æit√≠ API

**üü¢ LOW PRIORITY** (Budouc√≠ features):
8. **NanobanaProvider** - Image generation pro PRO+ tier
9. **VeoProvider** - Video generation pro ULTIMATE tier
10. **structlog** - Lep≈°√≠ logging (kosmetick√° zmƒõna)
11. **litellm gateway** - Multi-provider abstrakce (nen√≠ nutn√©)

### üèóÔ∏è ARCHITEKTONICK√ù ROZD√çL: Pl√°n vs Realita

**PL√ÅN v dokumentu:**

```
AIGateway (OOP Gateway Class)
    ‚îú‚îÄ‚îÄ GeminiProvider
    ‚îú‚îÄ‚îÄ PerplexityProvider
    ‚îú‚îÄ‚îÄ NanobanaProvider
    ‚îî‚îÄ‚îÄ CostTracker
```

**REALITA v k√≥du:**

```
Factory Functions (Funkcion√°ln√≠ p≈ô√≠stup)
    ‚îú‚îÄ‚îÄ get_text_provider() ‚Üí GeminiProvider
    ‚îî‚îÄ‚îÄ get_research_provider() ‚Üí PerplexityProvider

P≈ô√≠m√© pou≈æit√≠ provider≈Ø bez gateway layer
```

**Z√°vƒõr:** K√≥d funguje dob≈ôe s factory pattern p≈ô√≠stupem. Nen√≠ nutnƒõ pot≈ôeba vytv√°≈ôet OOP Gateway t≈ô√≠du, ale **CostTracker** a **AICache** jsou kritick√© pro produkƒçn√≠ pou≈æit√≠.

---

*Tento dokument je SELF-CONTAINED - obsahuje v≈°echny informace o AI integrac√≠ch.*

---

## üìÇ P≈òESN√Å STRUKTURA SOUBOR≈Æ A K√ìDU

### Skuteƒçn√° slo≈æka `providers/`

```bash
$ ls -lh apps/ai_gateway/providers/
total 52
-rw-r--r-- 1 root root  476 Dec 15 07:27 __init__.py
-rw-r--r-- 1 root root 4686 Dec 16 07:22 base.py
-rw-r--r-- 1 root root 4364 Dec 16 08:00 gemini.py
-rw-r--r-- 1 root root 5842 Dec 16 08:07 perplexity.py
```

### `__init__.py` (476 byt≈Ø) - Factory Functions

```python
"""Factory functions for AI providers."""
from apps.ai_gateway.providers.base import AIProvider
from apps.ai_gateway.providers.gemini import GeminiProvider
from apps.ai_gateway.providers.perplexity import PerplexityProvider

def get_text_provider() -> AIProvider:
    """Get the default text generation provider (Gemini)."""
    return GeminiProvider()

def get_research_provider() -> AIProvider:
    """Get the web research provider (Perplexity)."""
    return PerplexityProvider()
```

### `base.py` (4,686 byt≈Ø) - Base Classes

```python
"""Base classes for AI providers."""
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Any

@dataclass
class GenerationResult:
    """Result from AI generation."""
    content: str | dict
    input_tokens: int
    output_tokens: int
    model: str
    provider: str
    raw_response: Any = None

class AIProvider(ABC):
    """Base class for all AI providers."""
    
    @abstractmethod
    def generate_text(self, prompt: str, **kwargs) -> GenerationResult:
        """Generate text from prompt."""
        pass
    
    @abstractmethod
    def generate_json(self, prompt: str, schema: dict) -> dict:
        """Generate structured JSON output."""
        pass
```

### `gemini.py` (4,364 byt≈Ø) - Gemini Provider

**Status:** ‚úÖ Plnƒõ funkƒçn√≠

```python
"""Google Gemini provider for text generation."""
import logging
import google.genai as genai
from django.conf import settings

from apps.ai_gateway.providers.base import AIProvider, GenerationResult

logger = logging.getLogger(__name__)

class GeminiProvider(AIProvider):
    """Gemini 1.5 Pro provider."""
    
    def __init__(self):
        self.client = genai.Client(api_key=settings.GEMINI_API_KEY)
        self.model = "gemini-1.5-pro-002"
    
    def generate_text(self, prompt: str, max_tokens: int = 4096, **kwargs) -> GenerationResult:
        """Generate text using Gemini."""
        response = self.client.models.generate_content(
            model=self.model,
            contents=prompt,
            config=genai.types.GenerateContentConfig(
                max_output_tokens=max_tokens,
            )
        )
        
        return GenerationResult(
            content=response.text,
            input_tokens=response.usage_metadata.prompt_token_count,
            output_tokens=response.usage_metadata.candidates_token_count,
            model=self.model,
            provider="gemini",
            raw_response=response,
        )
    
    def generate_json(self, prompt: str, schema: dict) -> dict:
        """Generate structured JSON."""
        # Implementation with JSON mode
        ...
```

### `perplexity.py` (5,842 byt≈Ø) - Perplexity Provider

**Status:** ‚úÖ Plnƒõ funkƒçn√≠

```python
"""Perplexity API provider for web search."""
import logging
import httpx
from django.conf import settings

from apps.ai_gateway.providers.base import AIProvider, GenerationResult

logger = logging.getLogger(__name__)

class PerplexityProvider(AIProvider):
    """Perplexity Sonar provider for web search."""
    
    def __init__(self):
        self.api_key = settings.PERPLEXITY_API_KEY
        self.base_url = "https://api.perplexity.ai"
        self.model = "llama-3.1-sonar-large-128k-online"
    
    def generate_text(self, prompt: str, **kwargs) -> GenerationResult:
        """Search the web and generate response."""
        with httpx.Client() as client:
            response = client.post(
                f"{self.base_url}/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json",
                },
                json={
                    "model": self.model,
                    "messages": [
                        {"role": "user", "content": prompt}
                    ],
                },
                timeout=60.0,
            )
            response.raise_for_status()
            data = response.json()
        
        return GenerationResult(
            content=data["choices"][0]["message"]["content"],
            input_tokens=data.get("usage", {}).get("prompt_tokens", 0),
            output_tokens=data.get("usage", {}).get("completion_tokens", 0),
            model=self.model,
            provider="perplexity",
            raw_response=data,
        )
    
    def generate_json(self, prompt: str, schema: dict) -> dict:
        """Generate structured JSON with web search."""
        # Adds schema instructions to prompt
        result = self.generate_text(prompt + "\n\nReturn ONLY valid JSON.")
        return json.loads(result.content)
```

### `models.py` - AIJob Model (NE PromptTemplate!)

**Status:** ‚úÖ Existuje pro job tracking

```python
"""AI Gateway models."""
from django.db import models
from apps.core.models import BaseModel

class JobStatus(models.TextChoices):
    PENDING = 'pending', 'Pending'
    PROCESSING = 'processing', 'Processing'
    COMPLETED = 'completed', 'Completed'
    FAILED = 'failed', 'Failed'
    CANCELLED = 'cancelled', 'Cancelled'

class JobType(models.TextChoices):
    SCRAPE_DNA = 'scrape_dna', 'Scrape Company DNA'
    GENERATE_PERSONAS = 'generate_personas', 'Generate Personas'
    GENERATE_TOPICS = 'generate_topics', 'Generate Topics'
    GENERATE_BLOGPOST = 'generate_blogpost', 'Generate Blog Post'
    GENERATE_SOCIAL = 'generate_social', 'Generate Social Posts'
    GENERATE_IMAGE = 'generate_image', 'Generate Image'
    GENERATE_VIDEO = 'generate_video', 'Generate Video'

class AIJob(BaseModel):
    """Tracks AI generation jobs with Celery integration."""
    company = models.ForeignKey('companies.Company', on_delete=models.CASCADE)
    created_by = models.ForeignKey('users.User', on_delete=models.SET_NULL, null=True)
    
    job_type = models.CharField(max_length=30, choices=JobType.choices)
    status = models.CharField(max_length=20, choices=JobStatus.choices)
    
    input_data = models.JSONField(default=dict)
    output_data = models.JSONField(default=dict)
    
    error_message = models.TextField(blank=True)
    error_details = models.JSONField(default=dict)
    
    started_at = models.DateTimeField(null=True, blank=True)
    completed_at = models.DateTimeField(null=True, blank=True)
    
    retry_count = models.IntegerField(default=0)
    max_retries = models.IntegerField(default=3)
    
    celery_task_id = models.CharField(max_length=255, blank=True)
    priority = models.IntegerField(default=5)
    
    tokens_used = models.IntegerField(default=0)
    generation_time_seconds = models.FloatField(null=True, blank=True)
```

### `services.py` - Business Logic (s hardcoded prompty!)

**Status:** ‚úÖ Funguje, ale prompty jsou hardcoded

```python
"""AI Gateway services."""
import logging
from apps.ai_gateway.providers import get_text_provider, get_research_provider

logger = logging.getLogger(__name__)

def scrape_company_dna(*, website: str, company_name: str) -> dict:
    """Scrape company DNA using Perplexity."""
    provider = get_research_provider()
    
    # ‚ùå HARDCODED PROMPT (mƒõl by b√Ωt v DB jako PromptTemplate!)
    prompt = f"""Research the company "{company_name}" with website {website}.

Find and return comprehensive information about:

1. **Mission & Vision**
   - Company mission statement
   - Company vision
   - Core purpose

2. **Values & Culture**
   - Core company values
   - Company culture aspects

3. **Target Audience**
   - Primary customer segments
   - Customer pain points
   - Customer desires/goals

4. **Business Details**
   - Industry/niche
   - Main products or services
   - Unique selling proposition (USP)

5. **Brand Voice**
   - Communication style (formal vs casual)
   - Tone (serious vs playful)
   - Key messaging themes

6. **Competitors**
   - Main competitors in the market

Be thorough and accurate. If information is not available, indicate "Not found".
"""
    
    # ‚ùå HARDCODED SCHEMA (mƒõlo by b√Ωt v PromptTemplate!)
    schema = {
        'mission': 'string - Company mission statement',
        'vision': 'string - Company vision',
        'values': ['string - Core value'],
        'target_audience': 'string - Description',
        'audience_pain_points': ['string - Pain point'],
        'audience_desires': ['string - Desire/goal'],
        'industry': 'string - Industry/niche',
        'products_services': ['string - Product or service'],
        'usp': 'string - Unique selling proposition',
        'tone_formal_casual': 'number 0-100',
        'tone_serious_playful': 'number 0-100',
        'content_themes': ['string - Content theme'],
        'competitors': ['string - Competitor name'],
    }
    
    result = provider.generate_json(prompt, schema)
    
    # Add defaults for missing fields
    defaults = {
        'mission': '', 'vision': '', 'values': [],
        'target_audience': '', 'audience_pain_points': [],
        'audience_desires': [], 'industry': '',
        'products_services': [], 'usp': '',
        'tone_formal_casual': 50, 'tone_serious_playful': 50,
        'content_themes': [], 'competitors': [],
    }
    
    for key, default in defaults.items():
        if key not in result or result[key] is None:
            result[key] = default
    
    return result


def generate_personas(*, company_dna: dict, count: int = 6) -> list[dict]:
    """Generate personas based on company DNA."""
    provider = get_text_provider()
    
    tone_formality = 'Casual' if company_dna.get('tone_formal_casual', 50) > 50 else 'Formal'
    tone_mood = 'Playful' if company_dna.get('tone_serious_playful', 50) > 50 else 'Serious'
    
    # ‚ùå DAL≈†√ç HARDCODED PROMPT!
    prompt = f"""Create {count} unique fictional author personas for content creation.

Company Information:
- Name: {company_dna.get('name', 'Unknown')}
- Industry: {company_dna.get('industry', 'General')}
- Mission: {company_dna.get('mission', 'Not specified')}
- Vision: {company_dna.get('vision', 'Not specified')}
- Values: {', '.join(company_dna.get('values', []))}
- Target Audience: {company_dna.get('target_audience', 'General audience')}
- USP: {company_dna.get('usp', 'Not specified')}
- Tone: {tone_formality}, {tone_mood}

Requirements for each persona:
1. **Unique Identity**: Distinct name and background
2. **Psychology**: Jung archetype and MBTI type that align with brand
3. **Personal Values**: 3-5 values that resonate with the company
4. **Writing Style**: Specific vocabulary level, sentence style, formality
5. **Visual Style**: Description for image generation
6. **Expertise**: 3-5 topics they're experts in

Make personas diverse but all aligned with the company's brand voice.
Include a mix of archetypes to cover different content angles.

Jung Archetypes: innocent, everyman, hero, outlaw, explorer, creator, ruler, 
magician, lover, caregiver, jester, sage

MBTI types: INTJ, INTP, ENTJ, ENTP, INFJ, INFP, ENFJ, ENFP, ISTJ, ISFJ, 
ESTJ, ESFJ, ISTP, ISFP, ESTP, ESFP
"""
    
    # ‚ùå HARDCODED SCHEMA
    schema = {
        'personas': [
            {
                'name': 'string - Full name',
                'bio': 'string - 2-3 sentence biography',
                'archetype': 'string - Jung archetype (lowercase)',
                'mbti': 'string - MBTI type (4 letters uppercase)',
                'values': ['string - Personal value'],
                'frustrations': ['string - What frustrates them'],
                'vocabulary_level': 'string - simple|professional|academic',
                # ... v√≠ce fields
            }
        ]
    }
    
    result = provider.generate_json(prompt, schema)
    return result['personas']
```

---

## üéØ KL√çƒåOV√â ZJI≈†TƒöN√ç

### ‚úÖ Co funguje v√Ωbornƒõ

1. **Provider implementace** - GeminiProvider a PerplexityProvider jsou solidn√≠
2. **Factory pattern** - ƒåist√Ω, jednoduch√Ω p≈ô√≠stup bez zbyteƒçn√© abstrakce
3. **AIJob model** - Dobr√Ω z√°klad pro async job tracking s Celery
4. **Token tracking** - Data jsou k dispozici z API responses

### ‚ùå Nejvƒõt≈°√≠ probl√©my

1. **Hardcoded prompty** - V≈°echny prompty jsou v `services.py`, ne v DB
   - Nelze upravovat bez code deploy
   - ≈Ω√°dn√© verzov√°n√≠ nebo A/B testing
   - Content mana≈æer nem≈Ø≈æe upravit

2. **≈Ω√°dn√Ω cost tracking** - I kdy≈æ m√°me `tokens_used` v `AIJob`, nen√≠ agregace
   - Chyb√≠ monthly summary per company
   - Nen√≠ billing integration

3. **≈Ω√°dn√Ω caching** - Opakovan√© requesty jdou znovu na API
   - Zbyteƒçn√© n√°klady
   - Pomalej≈°√≠ response

### üí° Quick Wins

1. **AICache** - Implementace za 1-2 hodiny, okam≈æit√° √∫spora
2. **CostTracker** - Data u≈æ m√°me, jen p≈ôidat persistov√°n√≠
3. **PromptTemplate model** - Umo≈æn√≠ non-tech editaci prompt≈Ø

---

*Tento dokument nyn√≠ obsahuje KOMPLETN√ç informace o pl√°novan√© architektu≈ôe I skuteƒçn√©m stavu implementace.*
